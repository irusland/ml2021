{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Регуляризация xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Более подробно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Данный регуляризатор подобран эвристически и хорошо показывает себя на практике. \n",
    "\n",
    "Раскладывая в ряд Тейлора выражение $\\mathcal{L}\\left(y_i, \\hat{y}_i^{\\left(t-1\\right)} + b_t(x_i)\\right)$ до второго порядка, получаем:\n",
    "\n",
    "$$ Obj^{(t)} = \\sum_{i=1}^N\\left[\\mathcal{L}(y_i, \\hat{y}_i^{\\left(t-1\\right)}) + g_{i}b_{t}(x_i) + \\frac{1}{2}h_{i}b_{t}^2(x_i)\\right] + \\Omega(b_t),$$\n",
    "\n",
    "где $g_i = \\partial_{\\hat{y}_i^{(t-1)}} \\mathcal{L}(y_i, \\hat{y_i}^{(t-1)})$, $h_i = \\partial_{\\hat{y}_i^{(t-1)}}^2 \\mathcal{L}(y_i, \\hat{y}_i^{(t-1)}) $ — градиент и гессиан оптимизируемой функции потерь.\n",
    "\n",
    "Приводя теперь подобные слагаемые и отбрасывая слагаемое $ \\mathcal{L}(y_i, \\hat{y}_i^{(t-1)}) $, не зависящее от $ b_t(x_i)$ (а следовательно, не влияющее на точку минимума функционала), получаем формулу:\n",
    "$$ Obj^{(t)} = \\Big[\\sum_{i=1}^N\\mathcal{L}(y_i, \\hat{y}_i^{\\left(t-1\\right)})\\Big] + \\sum_{i=1}^N\\Big[g_{i}b_{t}(x_i) + \\frac{1}{2}h_{i}b_{t}^2(x_i)\\Big] + \\Big[\\gamma T + \\frac{1}{2}\\lambda\\sum_{j=1}^{T}w_j^2 + \\alpha\\sum_{j=1}^{T}|w_j|\\Big]$$\n",
    "\n",
    "Сделаем хитрый трюк: рассмотрим все объекты, через листья, в которые они попали ($I_j$ - множество объектов, попвших в лист $j$)\n",
    "$$\\sum_{i=1}^{N}g_ib_t(x_i) = \\sum_{j=1}^{T}w_j\\sum_{i\\in I_j}g_i = \\sum_{j=1}^{T}w_jG_j$$\n",
    "$$\\sum_{i=1}^{N}h_ib_t^2(x_i) = \\sum_{j=1}^{T}w^2_j\\sum_{i\\in I_j}h_i = \\sum_{j=1}^{T}w_jH_j$$\n",
    "\n",
    "\n",
    "Тогда получим\n",
    "\n",
    "$$ Obj^{(t)} = \\Big[\\sum_{i=1}^N\\mathcal{L}(y_i, \\hat{y}_i^{\\left(t-1\\right)})\\Big] + \\sum_{j=1}^{T}\\left[G_jw_j + \\frac{1}{2}(H_j + \\lambda)w_j^2 + \\alpha|w_j|\\right] + \\gamma T, $$\n",
    "\n",
    "Заметим, что первое слагаемое не зависит от текущего оптимизируемого дерева $b_t$, значит его можно отбросить и минимизировать оставшийся функционал\n",
    "\n",
    "$$ \\tilde{Obj}^{(t)} = \\sum_{j=1}^{T}\\left[G_jw_j + \\frac{1}{2}(H_j + \\lambda)w_j^2 + \\alpha|w_j|\\right] + \\gamma T \\rightarrow \\min$$\n",
    "\n",
    "\n",
    "Теперь, имея заданную структуру дерева, можно аналитически вычислить оптимальные значения для весов.\n",
    "\n",
    "В общем случае получаем:\n",
    "$$ w_j = \\begin{cases}\n",
    "-\\frac{G_j + \\alpha}{H_j + \\lambda}, если \\space G_j < -\\alpha, \\\\\n",
    "-\\frac{G_j - \\alpha}{H_j + \\lambda}, если \\space G_j > \\alpha, \\\\\n",
    "0, \\space иначе.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "При $\\alpha = 0$:\n",
    "$$ w_j^* = -\\frac{G_j}{H_j + \\lambda}.$$\n",
    "\n",
    "Значение функционала при $\\alpha = 0$ будет равно:\n",
    "\n",
    "$$ Obj = -\\frac{1}{2}\\sum_{j=1}^T \\frac{G_j^2}{H_j + \\lambda} + \\gamma T .$$\n",
    "\n",
    "Осталось только построить дерево оптимальной структуры. Это можно делать известными методами построения решающих деревьев, проводя разбиения таким образом, чтобы максимизировать gain, определенный как уменьшение $Obj$ в момент этого разбиения. Для уже построенного дерева по формулам $ w_j^* $ вычисляются оптимальные значения в листьях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. X-regularization (extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разберемся со сложной бустинговой регулризацией. \n",
    "У нас есть реальные значения $y$ и некоторый неполный алгоритм $a$, который выдает по объектам значения $y^a$ ($y_i^{(t-1)}$ в теории)\n",
    "\n",
    "Мы создаем следующее дерево решений и оно как-то разбивает наши объекты на листья. (Разбение таргетов $Tree$ - содержит индексы объектов, а не сами объекты)\n",
    "\n",
    "Необходимо подсчитать функционал и новые оптимальные веса объектов.\n",
    "$$ Q = -\\frac{1}{2}\\sum_{j=1}^T \\frac{G_j^2}{H_j + \\lambda} + \\gamma T$$\n",
    "\n",
    "$$ w_j^* = -\\frac{G_j}{H_j + \\lambda}$$\n",
    "\n",
    "* $T$ — количество листьев в текущем дереве\n",
    "* $\\lambda, \\gamma$ — гиперпараметры\n",
    "* $G_j = \\sum_{i\\in I_j}g_i$ - сумма градиентов в одном листе по $g_i = \\partial_{\\hat{y}_i^a} \\mathcal{L}(y_i, \\hat{y}_i^a)$\n",
    "* $H_j = \\sum_{i\\in I_j}h_i$ - сумма гессианов в одном листе по $h_i = \\partial_{\\hat{y}_i^a}^2 \\mathcal{L}(y_i, \\hat{y}_i^a) $\n",
    "* $\\mathcal{L}(y_i, \\hat{y}_i^a) = (y_i - \\hat{y}_i^a)^2$\n",
    "* $\\hat{y}_i^a$ - значение **уже собранного** алгоритма \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xregul(y, y_prev, Tree, gamma, lamb):\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    return Q, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamb = 0.5\n",
    "gamma = 0.5\n",
    "y = np.array([2, 4, 6, 8, 24, 26, 28, 34])\n",
    "y_prev = np.array([5, 5, 5, 5, 27, 27, 27, 27])\n",
    "Tree = np.array([np.array([0, 1, 2]), \n",
    "                 np.array([3]), \n",
    "                 np.array([4, 5, 6]), \n",
    "                 np.array([7])])\n",
    "\n",
    "\n",
    "Q, w = xregul(y, y_prev, Tree, gamma, lamb)\n",
    "    \n",
    "assert (Q - -50) < 0.1\n",
    "assert_almost_equal(w, np.array([-0.92, 2.4, -0.92, 5.6]), 2)\n",
    "\n",
    "#########################################\n",
    "lamb = 0.5\n",
    "gamma = 0.5\n",
    "y = np.array([2, 4, 6, 8, 24, 26, 28, 34])\n",
    "y_prev = np.array([3, 3, 7, 7, 26, 26, 26, 34])\n",
    "Tree = np.array([np.array([0, 1, 2]), \n",
    "                 np.array([3]), \n",
    "                 np.array([4, 5, 6]), \n",
    "                 np.array([7])])\n",
    "\n",
    "\n",
    "Q, w = xregul(y, y_prev, Tree, gamma, lamb)\n",
    "    \n",
    "assert (Q - 0.89) < 0.1\n",
    "assert_almost_equal(w, np.array([-0.3, 0.8, 0, 0]), 2)\n",
    "#########################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
