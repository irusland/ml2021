{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.testing import assert_array_equal, assert_array_almost_equal, assert_equal, assert_almost_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (1) Каннабола"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[DISCLAIMER](https://gist.githubusercontent.com/justheuristic/e2c1fa28ca02670cabc42cacf3902796/raw/fd3d935cef63a01b85ed2790b5c11c370245cbd7/stddisclaimer.h)\n",
    "\n",
    "Запишите функцию каннаболы в полярных координатах\n",
    "$$\\rho(\\theta) = (1 + 0.9 \\cdot cos (8 \\cdot \\theta) ) \\cdot (1 + 0.1 \\cdot cos(24 \\cdot \\theta)) \\cdot (0.9 + 0.05 \\cdot cos(200 \\cdot \\theta)) \\cdot (1 + sin(\\theta))$$\n",
    "\n",
    "А также переведите ее в обычные координаты ([howto](http://www.mathsisfun.com/polar-cartesian-coordinates.html))\n",
    "\n",
    "Используйте только тензоры торча: никаких листов циклов и нампи массивов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "mfypiG0aiei-",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'assert_no_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-910bec2261e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#precondition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0massert_no_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'print'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'while'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'map'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'for'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'open'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'numpy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'np'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'assert_no_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "#precondition\n",
    "assert_no_tokens(['print', 'while', 'map', 'for', 'open', 'numpy', 'np'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cannabola(theta: torch.Tensor) -> torch.Tensor:\n",
    "    rho = (1 + 0.9*torch.cos(8*theta)) * (1 + 0.1*torch.cos(24*theta))* (0.9 + 0.05*torch.cos(200*theta))*(1 + torch.sin(theta))\n",
    "    x =   rho*torch.cos(theta)\n",
    "    y =   rho*torch.sin(theta)\n",
    "    return rho, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(p,m,c):\n",
    "    return (p + m*torch.cos(c))\n",
    "def cannabola(theta: torch.Tensor) -> torch.Tensor:\n",
    "    rho = f(1,0.9,8*theta) *    f(1,0.1,24*theta)*    f(0.9, 0.05, 200*theta)*    (1 + torch.sin(theta))\n",
    "    return rho, rho*torch.cos(theta), rho*torch.sin(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = torch.linspace(- np.pi, np.pi, steps=1000)\n",
    "\n",
    "rho, x, y = cannabola(theta)\n",
    "\n",
    "rho_corr = torch.FloatTensor([1.9855, 1.8980, 1.7622, 1.7372, 1.8181, 1.8476,\n",
    "                              1.7383, 1.5899, 1.5458, 1.5965, 1.6020, 1.4901])\n",
    "\n",
    "assert torch.allclose(rho[:12], rho_corr, atol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[6,6])\n",
    "plt.fill(x.numpy(), y.numpy(), color='green')\n",
    "plt.grid()\n",
    "\n",
    "print('Weeeeeell Doooooone!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVYmABv0iei2"
   },
   "source": [
    "# SLIDE (1) Ближайший элемент (опять)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LElWGGt-iei5"
   },
   "source": [
    "`Ah shit, here we go again.`\n",
    "\n",
    "Реализуйте функцию, принимающую на вход непустой тензор (может быть многомерным) $X$ и некоторое число $a$ и возвращающую ближайший к числу элемент тензора. Если ближайших несколько - выведите минимальный из ближайших. (Вернуть нужно само число, а не индекс числа!)\n",
    "\n",
    "### Sample\n",
    "#### Input:\n",
    "```python\n",
    "X = torch.Tensor([[ 1.  2. 13.]\n",
    "                  [15.  6.  8.]\n",
    "                  [ 7. 18.  9.]])\n",
    "a = 7.2\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "7\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YNJOwNUiei8"
   },
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfypiG0aiei-"
   },
   "outputs": [],
   "source": [
    "#precondition\n",
    "assert_no_tokens(['print', 'while', 'map', 'for', 'open', 'numpy', 'np'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "z3U1Ap6XiejD"
   },
   "outputs": [],
   "source": [
    "def nearest_value(X: torch.Tensor, a: float) -> torch.Tensor:\n",
    "    print(abs(X - a))\n",
    "    idx = torch.argmin(abs(X - a), dim=1)\n",
    "    print(idx, )\n",
    "    print(X[idx])\n",
    "    print()\n",
    "    return X[idx].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_value(X: torch.Tensor, a: float) -> torch.Tensor:\n",
    "    result = torch.where(abs(X - a) == abs(X - a).min())\n",
    "    return X[result][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "zpR66UkEiejO"
   },
   "outputs": [],
   "source": [
    "######################################################\n",
    "assert_equal(\n",
    "    nearest_value(torch.Tensor([ 1,  2, 13]), 10).numpy(), \n",
    "    13)\n",
    "######################################################\n",
    "assert_equal(\n",
    "    nearest_value(torch.Tensor([ -1,  0]), -0.5).numpy(), \n",
    "    -1)\n",
    "######################################################\n",
    "assert_equal(\n",
    "    nearest_value(torch.Tensor([[[ 1], [2],[3]],[[4],[5],[6]]]), 4.5).numpy(),\n",
    "    4)\n",
    "######################################################\n",
    "assert_equal(\n",
    "    nearest_value(torch.Tensor([[ 1,  2, 13],\n",
    "                                [15,  6,  8],\n",
    "                                [ 7, 18,  9]]), 7.2).numpy(),\n",
    "    7)\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (1) Взятие производной"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите производную функции\n",
    "$$ f(x) = \\frac{\\ln(arctan(x))}{arcsin^2(x)} $$\n",
    "Вам на вход подается одномерный тензор X c числами от 0 до 1. \n",
    "\n",
    "Верните одномерный тензор с значениями производной в этих точках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfypiG0aiei-"
   },
   "outputs": [],
   "source": [
    "#precondition\n",
    "assert_no_tokens(['print', 'while', 'map', 'for', 'open', 'numpy', 'np'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "z3U1Ap6XiejD"
   },
   "outputs": [],
   "source": [
    "def derivative(X: torch.Tensor) -> torch.Tensor:\n",
    "    X= X.requires_grad_(True)\n",
    "    f = torch.log(torch.arctan(X)) / (torch.arcsin(X) * torch.arcsin(X))\n",
    "    f.backward(gradient=torch.ones_like(f))\n",
    "    return X.grad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(0.1, 0.9, 9)\n",
    "\n",
    "dfdx = derivative(x)\n",
    "\n",
    "answer = torch.FloatTensor([5.6019e+03, 5.2582e+02, 1.2528e+02, 4.3635e+01, 1.8659e+01, 9.0595e+00,\n",
    "        4.7899e+00, 2.6957e+00, 1.6171e+00])\n",
    "\n",
    "assert torch.allclose(dfdx, answer, atol=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (1) Сборка сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберите и верните нейросеть [по рисунку](https://github.com/samstikhin/ml2021/blob/master/07-NN/images/homeNN.png). \n",
    "\n",
    "<img src=\"images/homeNN.png\" width=600 />\n",
    "\n",
    "В сети используются только линейные слои."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfypiG0aiei-"
   },
   "outputs": [],
   "source": [
    "#precondition\n",
    "assert_no_tokens(['print', 'while', 'map', 'for', 'open', 'numpy', 'np'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "z3U1Ap6XiejD"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-330e860fcdb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnet_by_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     return Sequential(\n\u001b[1;32m      5\u001b[0m         \u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from torch.nn import Sequential, Linear\n",
    "\n",
    "def net_by_png() -> torch.nn.Sequential:\n",
    "    return Sequential(\n",
    "        Linear(4, 4),\n",
    "        Linear(4, 5),\n",
    "        Linear(5, 6),\n",
    "        Linear(6, 4),\n",
    "        Linear(4, 3),\n",
    "        Linear(3, 3),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net_by_png()\n",
    "\n",
    "for layer in model:\n",
    "    layer.weight.data.fill_(1)\n",
    "    layer.bias.data.fill_(1)\n",
    "\n",
    "\n",
    "x = torch.FloatTensor([[1,2,3,4],[-1,2,-3,4]])\n",
    "result = model(x).detach()\n",
    "\n",
    "answer = torch.FloatTensor([[16288., 16288., 16288.],\n",
    "                            [ 4768.,  4768.,  4768.]])\n",
    "\n",
    "assert torch.allclose(result, answer, atol=1e-2)\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "x = torch.FloatTensor([[1,-2,-3,-4],[-1,0,1,56]])\n",
    "result = model(x).detach()\n",
    "\n",
    "answer = torch.FloatTensor([[-9632., -9632., -9632.],\n",
    "                            [82528., 82528., 82528.]])\n",
    "\n",
    "assert torch.allclose(result, answer, atol=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (2) Линейный слой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам надо реализовать линейный слой (матричное умножение) нейронной сети.\n",
    "\n",
    "У нас есть 3 шага: \n",
    "\n",
    "* Forward: на вход получаем объект-вектор и пускаем его через веса (матричное умножение). $u_{current} = Wx$\n",
    "\n",
    "* Backward: получили ошибки (градиенты по выходам) с прошлого слоя $\\varepsilon_{last} = \\frac{\\partial L}{\\partial u_{last}}$ ($u_{last}$ - вектор значений выходов на предыдущем слое). Теперь нам надо посчитать градиенты на текущем слое (пустить ошибку назад). В этом случае у нас также происходит матричное умножение, только не объекта, а градиентов. $\\varepsilon_{new} = W^T\\varepsilon_{last}$\n",
    "\n",
    "<img src=\"images/backward.png\" width=200 />\n",
    "\n",
    "* Gradient weights. Запись градиентов весов. $\\frac{\\partial L}{\\partial W} = \\frac{\\partial L}{\\partial u_{current}}\\frac{\\partial u_{current}}{\\partial W} = \\varepsilon_{current}x$\n",
    "\n",
    "\n",
    "Как вы заметили на паре через модель можно пускать несколько объектов, поэтому ваша задача сделать операции используя `broadcasting`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, n_in, n_out):#инициализацию трогать не надо\n",
    "        stdv = 1./np.sqrt(n_in)\n",
    "        self.W = np.random.uniform(-stdv, stdv, size = (n_out, n_in)) # веса - произвольные\n",
    "        self.b = np.random.uniform(-stdv, stdv, size = n_out)      \n",
    "        self.gradW = np.zeros_like(self.W) # градиенты изначально нули\n",
    "        self.gradb = np.zeros_like(self.b) \n",
    "        \n",
    "    def forward(self, input: np.ndarray): #input batch x n_in\n",
    "        self.output = np.dot(self.W, input.T).T + self.b\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, gradOutput: np.ndarray): #gradOutput batch x n_out\n",
    "        self.gradInput = np.dot(self.W.T , gradOutput.T).T\n",
    "        return self.gradInput\n",
    "    \n",
    "    def findGrads(self, input: np.ndarray, gradOutput: np.ndarray): #gradOutput dL/dy\n",
    "        self.gradW = np.dot(gradOutput.T, input)\n",
    "        self.gradb = gradOutput[0] + gradOutput[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.028863  -0.9616457 -2.6107163 -1.1220281]\n",
      " [ 3.6259096  1.5735433 -2.7098317 -2.4890358]] \n",
      " [[ 1.028863  -0.9616457 -2.6107163 -1.1220281]\n",
      " [ 3.6259096  1.5735433 -2.7098317 -2.4890358]]\n",
      "[[ 9.308203   -4.118804   28.741945  ]\n",
      " [34.169224    6.940631   33.853695  ]\n",
      " [23.190228    0.61490536 36.279137  ]\n",
      " [67.4363     16.23861    58.561417  ]]\n",
      "[[ 9.308203   -4.118804   28.741945  ]\n",
      " [34.169224    6.940631   33.853695  ]\n",
      " [23.190228    0.61490536 36.279137  ]\n",
      " [67.4363     16.23861    58.561417  ]]\n",
      "[[-1.9648808  0.3311599 -3.2028537 -0.8274535]\n",
      " [-1.4432663  2.4006686 -5.402667  -1.7296238]] \n",
      " [[-1.9648808  0.3311599 -3.2028537 -0.8274535]\n",
      " [-1.4432663  2.4006686 -5.402667  -1.7296238]]\n",
      "[[  5.6847234 -16.890886   26.921963 ]\n",
      " [-10.428085   76.8017    -51.78934  ]\n",
      " [ -3.2885022  -3.2132263 -14.892674 ]\n",
      " [ -1.1958554 -25.359352   -4.1466293]]\n",
      "[[  5.6847234 -16.890886   26.921963 ]\n",
      " [-10.428085   76.8017    -51.78934  ]\n",
      " [ -3.2885022  -3.2132263 -14.892674 ]\n",
      " [ -1.1958554 -25.359352   -4.1466293]]\n",
      "[[ 4.6302733  3.294025   7.119894  -0.8776911]\n",
      " [ 6.8121796  5.457317   1.871879   5.413114 ]] \n",
      " [[ 4.6302733  3.294025   7.119894  -0.8776911]\n",
      " [ 6.8121796  5.457317   1.871879   5.413114 ]]\n",
      "[[ -26.393822  -104.070496     5.292259 ]\n",
      " [   7.1032233  -12.259804    12.83247  ]\n",
      " [  56.604095    58.613712    46.91803  ]\n",
      " [  44.781727    -2.6071358   54.45958  ]]\n",
      "[[ -26.393822  -104.070496     5.292259 ]\n",
      " [   7.1032233  -12.259804    12.83247  ]\n",
      " [  56.604095    58.613712    46.91803  ]\n",
      " [  44.781727    -2.6071358   54.45958  ]]\n",
      "[[-2.3954659   0.62503105 -6.1970396  -3.7368412 ]\n",
      " [-0.33466816 -1.6806371  -5.739438   -4.5639715 ]] \n",
      " [[-2.3954659   0.62503105 -6.1970396  -3.7368412 ]\n",
      " [-0.33466816 -1.6806371  -5.739438   -4.5639715 ]]\n",
      "[[ 38.225697   -51.53524      0.32638788]\n",
      " [-23.131443    21.459919   -13.335783  ]\n",
      " [ 42.602055   -50.594604     9.6050205 ]\n",
      " [ 46.910854   -39.728714    32.168156  ]]\n",
      "[[ 38.225697   -51.53524      0.32638788]\n",
      " [-23.131443    21.459919   -13.335783  ]\n",
      " [ 42.602055   -50.594604     9.6050205 ]\n",
      " [ 46.910854   -39.728714    32.168156  ]]\n",
      "[[ 0.48703855  0.6585163  -0.87618196 -0.13997567]\n",
      " [-1.5386984  -0.77841663 -1.0532911  -3.7686467 ]] \n",
      " [[ 0.48703855  0.6585163  -0.87618196 -0.13997567]\n",
      " [-1.5386984  -0.77841663 -1.0532911  -3.7686467 ]]\n",
      "[[-43.824863   26.64632   -30.04213  ]\n",
      " [  3.8367023  -9.775595  -39.93358  ]\n",
      " [ 55.925056  -31.255905   54.049488 ]\n",
      " [-56.769344   31.470467  -56.336884 ]]\n",
      "[[-43.824863   26.64632   -30.04213  ]\n",
      " [  3.8367023  -9.775595  -39.93358  ]\n",
      " [ 55.925056  -31.255905   54.049488 ]\n",
      " [-56.769344   31.470467  -56.336884 ]]\n",
      "[[ 0.42464828  0.55650204  1.5037884  -0.88296235]\n",
      " [ 1.3937283  -1.6665304  -1.3187414  -0.07749072]] \n",
      " [[ 0.42464828  0.55650204  1.5037884  -0.88296235]\n",
      " [ 1.3937283  -1.6665304  -1.3187414  -0.07749072]]\n",
      "[[ -9.534893  -5.791786 -11.934523]\n",
      " [ 44.639553  12.84166   -9.872623]\n",
      " [ 45.765327  25.915943  48.608242]\n",
      " [ 61.805508  14.575673 -28.427956]]\n",
      "[[ -9.534893  -5.791786 -11.934523]\n",
      " [ 44.639553  12.84166   -9.872623]\n",
      " [ 45.765327  25.915943  48.608242]\n",
      " [ 61.805508  14.575673 -28.427956]]\n",
      "[[ 4.0853004   2.6665463  -2.5272484  -1.6748831 ]\n",
      " [ 1.0240269   0.9653562  -0.22588001  0.25975436]] \n",
      " [[ 4.0853004   2.6665463  -2.5272484  -1.6748831 ]\n",
      " [ 1.0240269   0.9653562  -0.22588001  0.25975436]]\n",
      "[[ 58.717148  -67.18074    30.448246 ]\n",
      " [ 17.525543  -25.075165   16.45085  ]\n",
      " [ -1.8819928   6.784635   -7.7640758]\n",
      " [  5.9715967 -18.718855   20.518557 ]]\n",
      "[[ 58.717148  -67.18074    30.448246 ]\n",
      " [ 17.525543  -25.075165   16.45085  ]\n",
      " [ -1.8819928   6.784635   -7.7640758]\n",
      " [  5.9715967 -18.718855   20.518557 ]]\n",
      "[[ 4.723407  -7.254607  -4.4724874  2.754867 ]\n",
      " [-3.0557196 -1.0669703  3.6667643  3.4510522]] \n",
      " [[ 4.723407  -7.254607  -4.4724874  2.754867 ]\n",
      " [-3.0557196 -1.0669703  3.6667643  3.4510522]]\n",
      "[[ -2.0116546 -21.609098   16.14512  ]\n",
      " [-10.191476   46.16707   -51.027386 ]\n",
      " [ 79.33687    66.77138    33.55126  ]\n",
      " [ 46.61939    -6.927019   59.109264 ]]\n",
      "[[ -2.0116546 -21.609098   16.14512  ]\n",
      " [-10.191476   46.16707   -51.027386 ]\n",
      " [ 79.33687    66.77138    33.55126  ]\n",
      " [ 46.61939    -6.927019   59.109264 ]]\n",
      "[[-0.72756064 -4.1716323  -5.245212   -1.6175139 ]\n",
      " [-0.19428444  1.7090296  -0.28818676 -2.1085396 ]] \n",
      " [[-0.72756064 -4.1716323  -5.245212   -1.6175139 ]\n",
      " [-0.19428444  1.7090296  -0.28818676 -2.1085396 ]]\n",
      "[[-56.82948  -44.22764   -9.07691 ]\n",
      " [ 60.60068   42.58948   42.700787]\n",
      " [ 53.618126  38.306526  33.2727  ]\n",
      " [-41.45161  -34.147293   7.00861 ]]\n",
      "[[-56.82948  -44.22764   -9.07691 ]\n",
      " [ 60.60068   42.58948   42.700787]\n",
      " [ 53.618126  38.306526  33.2727  ]\n",
      " [-41.45161  -34.147293   7.00861 ]]\n",
      "[[ 5.9467373  -0.74900126 -0.56412935  1.7993561 ]\n",
      " [-0.05458921 -0.5693989   1.1022396  -3.2411728 ]] \n",
      " [[ 5.9467373  -0.74900126 -0.56412935  1.7993561 ]\n",
      " [-0.05458921 -0.5693989   1.1022396  -3.2411728 ]]\n",
      "[[ -22.859085    25.946766   -17.795267 ]\n",
      " [  20.467018    49.986504   -21.013702 ]\n",
      " [  62.71649    -17.577211    21.770687 ]\n",
      " [-101.22652      2.7893257  -22.230171 ]]\n",
      "[[ -22.859085    25.946766   -17.795267 ]\n",
      " [  20.467018    49.986504   -21.013702 ]\n",
      " [  62.71649    -17.577211    21.770687 ]\n",
      " [-101.22652      2.7893257  -22.230171 ]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(36)\n",
    "torch.manual_seed(36)\n",
    "\n",
    "batch_size, n_in, n_out = 2, 3, 4\n",
    "for _ in range(10):\n",
    "    # layers initialization\n",
    "    torch_layer = torch.nn.Linear(n_in, n_out)\n",
    "    \n",
    "    custom_layer = Linear(n_in, n_out)\n",
    "    custom_layer.W = torch_layer.weight.data.numpy()\n",
    "    custom_layer.b = torch_layer.bias.data.numpy()\n",
    "\n",
    "    layer_input     = np.random.uniform(-10, 10, (batch_size, n_in)).astype(np.float32)\n",
    "    next_layer_grad = np.random.uniform(-10, 10, (batch_size, n_out)).astype(np.float32)\n",
    "\n",
    "    # 1. check layer output\n",
    "    custom_layer_output = custom_layer.forward(layer_input)\n",
    "    \n",
    "    layer_input_var = torch.tensor(layer_input, requires_grad=True)\n",
    "    torch_layer_output_var = torch_layer(layer_input_var)\n",
    "    print( torch_layer_output_var.data.numpy(), \"\\n\", custom_layer_output)\n",
    "#     assert np.allclose(torch_layer_output_var.data.numpy(), custom_layer_output, atol=1e-6)\n",
    "\n",
    "    # 2. check layer input grad\n",
    "    custom_layer_grad = custom_layer.backward(next_layer_grad)\n",
    "    \n",
    "    torch_layer_output_var.backward(torch.from_numpy(next_layer_grad))\n",
    "    torch_layer_grad_var = layer_input_var.grad\n",
    "    assert np.allclose(torch_layer_grad_var.data.numpy(), custom_layer_grad, atol=1e-6)\n",
    "\n",
    "    # 3. check layer parameters grad\n",
    "    custom_layer.findGrads(layer_input, next_layer_grad)\n",
    "    \n",
    "    weight_grad = custom_layer.gradW\n",
    "    bias_grad = custom_layer.gradb\n",
    "    torch_weight_grad = torch_layer.weight.grad.data.numpy()\n",
    "    torch_bias_grad = torch_layer.bias.grad.data.numpy()\n",
    "    print(torch_weight_grad, weight_grad, sep='\\n')\n",
    "    assert np.allclose(torch_weight_grad, weight_grad, atol=1e-6)\n",
    "    assert np.allclose(torch_bias_grad, bias_grad, atol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (1) MSELoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной задаче вам нужно реализовать ваш любимый MSE, но теперь он еще должен уметь возвращать градиент по входящим переменным, чтобы его можно было использовать в нейросетях.\n",
    "\n",
    "Реализация должна быть написана на `numpy`, а не `torch`, чтобы вы сами взяли производную, а не вызывали backward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSECriterion():\n",
    "    def forward(self, input: np.array, target: np.array): # batch x n_in\n",
    "        self.input = input\n",
    "        self.target = target\n",
    "        loss = ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        return loss \n",
    " \n",
    "    def backward(self):\n",
    "        gradients  = ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(41)\n",
    "torch.manual_seed(41)\n",
    "\n",
    "batch_size, n_in, n_out = 5, 1, 1\n",
    "for _ in range(10):\n",
    "    # layers initialization\n",
    "    torch_layer = torch.nn.MSELoss()\n",
    "    my_layer = MSECriterion()\n",
    "\n",
    "    # input initialization\n",
    "    np_input  = np.random.uniform(-10, 10, (batch_size, 1))\n",
    "    np_target = np.random.uniform(-10, 10, (batch_size, 1))\n",
    "\n",
    "    tensor_input = torch.tensor(np_input, requires_grad=True)\n",
    "    tensor_target= torch.tensor(np_target)\n",
    "     \n",
    "    # 1. check layer output\n",
    "    \n",
    "    my_loss    = my_layer.forward(np_input, np_target)\n",
    "    torch_loss = torch_layer(tensor_input, tensor_target) #создали ноду с лоссом\n",
    "    \n",
    "    assert np.allclose(torch_loss.data.numpy(), my_loss, atol=1e-2)\n",
    "\n",
    "    # 2. check layer input grad\n",
    "    my_loss_grad = my_layer.backward()\n",
    "    \n",
    "    torch_loss.backward()\n",
    "    \n",
    "    assert np.allclose(tensor_input.grad.data.numpy(), my_loss_grad, atol=1e-2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (1) Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем SGD оптимизатор с улучшением Momentum. \n",
    "\n",
    "Вспоминаем как было на линейке. Благо сейчас градиент считать не нужно. \n",
    "\n",
    "Улучшение Momentum:\n",
    "$$ g_t = \\gamma g_{t - 1} + \\eta \\nabla_{w}L^i$$\n",
    "$$ w^{(t+1)} = w^{(t)} - g_t$$\n",
    "\n",
    "где\n",
    "\n",
    " - $\\eta$ — learning rate\n",
    " - $w$ — вектор параметров\n",
    " - $L$ — оптимизируемый функционал\n",
    " - $\\gamma$ — momentum term (обычно выбирается 0.9)\n",
    "\n",
    "\n",
    "- `list_of_weights`   - лист листов с массивом весов из вершины сети\n",
    "- `list_of_gradients` - лист листов с массивом градинтов весов из вершины сети\n",
    "- `config` - словарь с оптимизационными параметрами (`learning_rate` and `momentum`)\n",
    "- `state` - словарь, чтобы кэшировать градиенты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_momentum(list_of_weights: list, \n",
    "                 list_of_gradients: list, \n",
    "                 config: dict, \n",
    "                 state: dict):  \n",
    "    \n",
    "    state.setdefault('accumulated_grads', {})\n",
    "    \n",
    "    layer_index = 0 \n",
    "    for current_layer_weights, current_layer_grads in zip(list_of_weights, list_of_gradients): \n",
    "        for current_node_weights, current_node_grads in zip(current_layer_weights, current_layer_grads):\n",
    "            old_grad = state['accumulated_grads'].setdefault(layer_index, np.zeros_like(current_node_grad)) # g_{t-1}\n",
    "            \n",
    "            ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "            \n",
    "            layer_index += 1     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'current_node_grad' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-88a3cdfbc5bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0msgd_momentum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accumulated_grads'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.002\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-92-fc9c20a522d9>\u001b[0m in \u001b[0;36msgd_momentum\u001b[0;34m(list_of_weights, list_of_gradients, config, state)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcurrent_layer_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_layer_grads\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_of_gradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcurrent_node_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_node_grads\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_layer_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_layer_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mold_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accumulated_grads'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_node_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# g_{t-1}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'current_node_grad' is not defined"
     ]
    }
   ],
   "source": [
    "state = {}  \n",
    "config = {'learning_rate': 1e-3, 'momentum': 0.9}\n",
    "\n",
    "# У 2-х слойной сети 2 набора входов и 2 набора градиентов этих входов\n",
    "variables = [[np.arange(3).astype(np.float64)], \n",
    "             [np.array([1.]), np.array([1.]), np.array([1.])]]\n",
    "\n",
    "gradients = [[np.arange(3).astype(np.float64)], \n",
    "             [np.array([1.]), np.array([1.]), np.array([1.])]]\n",
    "\n",
    "\n",
    "sgd_momentum(variables, gradients, config, state)\n",
    "assert np.allclose(state['accumulated_grads'][0], np.array([0., 0.001, 0.002]))\n",
    "\n",
    "\n",
    "sgd_momentum(variables, gradients, config, state)\n",
    "assert np.allclose(state['accumulated_grads'][0], np.array([0., 0.0019, 0.0038]))\n",
    "\n",
    "\n",
    "sgd_momentum(variables, gradients, config, state)\n",
    "assert np.allclose(state['accumulated_grads'][0], np.array([0., 0.00271, 0.00542]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (1) Давай еще раз..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте и обучите нейросеть для регрессии на данных и верните обученную нейросеть.\n",
    "\n",
    "Не делайте сеть слишком большой, один-два слоя должно хватить. Функция простая. Ваше обучение должно уложиться в 10 секунд.\n",
    "\n",
    "Если не получается, можете поиграться с разными оптимайзерами и разными `learning rate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear, Sequential, Flatten\n",
    "\n",
    "def learningNN(X: torch.FloatTensor, y: torch.FloatTensor) -> torch.nn.Sequential:\n",
    "    print(X.size(), y.size())\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(3, 3),\n",
    "#         torch.nn.Linear(3, 3),\n",
    "        torch.nn.Linear(3, 1),\n",
    "        torch.nn.Flatten(0, 1)\n",
    "    )\n",
    "\n",
    "\n",
    "    # Обозначили лосс MSE \n",
    "    loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "\n",
    "    # Выбрали алгоритм оптимизации\n",
    "    learning_rate = 0.003\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.00003, momentum=0.9)\n",
    "\n",
    "    # Обучаем\n",
    "#     for input, target in dataset:\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(input)\n",
    "#         loss = loss_fn(output, target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "    for epoch in range(1000):\n",
    "\n",
    "        # 1. Forward\n",
    "        # 2. Loss\n",
    "        # 3. Zero Grad\n",
    "        # 4. Backward\n",
    "        # 5. Update Weights\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X) \n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "#             # Forward pass: все до последней ноды\n",
    "#         y_pred = model(xx) \n",
    "\n",
    "#         # Compute loss: финальная нода с лоссом\n",
    "#         loss = loss_fn(y_pred, y)\n",
    "\n",
    "#         # Обнулили градиенты с прошлой итерации\n",
    "#         model.zero_grad()    \n",
    "\n",
    "#         # Backward pass: просчитали градиенты назад\n",
    "#         loss.backward()\n",
    "\n",
    "#         # Update the weights using gradient descent. \n",
    "#         with torch.no_grad():\n",
    "#             for param in model.parameters():\n",
    "#                 param -= learning_rate * param.grad\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 3]) torch.Size([200])\n",
      "tensor([0.9946, 1.0028, 1.0110, 1.0191, 1.0273, 1.0354, 1.0436, 1.0517, 1.0598,\n",
      "        1.0679, 1.0759, 1.0840, 1.0920, 1.1000, 1.1080, 1.1160, 1.1239, 1.1319,\n",
      "        1.1398, 1.1476, 1.1555, 1.1633, 1.1711, 1.1788, 1.1865, 1.1942, 1.2018,\n",
      "        1.2094, 1.2170, 1.2245, 1.2320, 1.2395, 1.2469, 1.2543, 1.2616, 1.2689,\n",
      "        1.2761, 1.2833, 1.2904, 1.2975, 1.3046, 1.3116, 1.3185, 1.3254, 1.3322,\n",
      "        1.3390, 1.3457, 1.3523, 1.3589, 1.3655, 1.3720, 1.3784, 1.3847, 1.3910,\n",
      "        1.3972, 1.4034, 1.4095, 1.4155, 1.4214, 1.4273, 1.4331, 1.4388, 1.4445,\n",
      "        1.4500, 1.4555, 1.4610, 1.4663, 1.4716, 1.4768, 1.4819, 1.4869, 1.4918,\n",
      "        1.4966, 1.5014, 1.5061, 1.5107, 1.5151, 1.5195, 1.5239, 1.5281, 1.5322,\n",
      "        1.5362, 1.5401, 1.5440, 1.5477, 1.5513, 1.5549, 1.5583, 1.5616, 1.5648,\n",
      "        1.5679, 1.5709, 1.5738, 1.5766, 1.5793, 1.5819, 1.5843, 1.5867, 1.5889,\n",
      "        1.5910, 1.5930, 1.5949, 1.5967, 1.5983, 1.5998, 1.6012, 1.6025, 1.6037,\n",
      "        1.6047, 1.6056, 1.6064, 1.6070, 1.6075, 1.6079, 1.6081, 1.6083, 1.6082,\n",
      "        1.6081, 1.6078, 1.6074, 1.6068, 1.6061, 1.6052, 1.6043, 1.6031, 1.6019,\n",
      "        1.6004, 1.5989, 1.5971, 1.5953, 1.5933, 1.5911, 1.5888, 1.5863, 1.5837,\n",
      "        1.5809, 1.5780, 1.5749, 1.5716, 1.5682, 1.5647, 1.5609, 1.5570, 1.5530,\n",
      "        1.5488, 1.5444, 1.5398, 1.5351, 1.5302, 1.5251, 1.5199, 1.5145, 1.5089,\n",
      "        1.5031, 1.4972, 1.4911, 1.4848, 1.4783, 1.4717, 1.4648, 1.4578, 1.4506,\n",
      "        1.4432, 1.4356, 1.4279, 1.4199, 1.4118, 1.4035, 1.3950, 1.3862, 1.3773,\n",
      "        1.3682, 1.3589, 1.3494, 1.3398, 1.3299, 1.3198, 1.3095, 1.2990, 1.2883,\n",
      "        1.2774, 1.2663, 1.2550, 1.2434, 1.2317, 1.2197, 1.2076, 1.1952, 1.1826,\n",
      "        1.1698, 1.1568, 1.1436, 1.1301, 1.1165, 1.1026, 1.0885, 1.0741, 1.0596,\n",
      "        1.0448, 1.0298], grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Подготовили данные \n",
    "import math\n",
    "\n",
    "x = torch.linspace(1, math.pi, 200)\n",
    "y = torch.log(x) + torch.sin(x)\n",
    "p = torch.tensor([1, 2, 3])\n",
    "xx = x.unsqueeze(-1).pow(p)\n",
    "\n",
    "model = learningNN(xx, y)\n",
    "\n",
    "print( model(xx))\n",
    "v = torch.nn.MSELoss()(y, model(xx))\n",
    "assert v < 0.05, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a5aedad14f4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# просто рисовалка\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'polynom'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# просто рисовалка   \n",
    "plt.plot(x, y, label='sin')\n",
    "plt.plot(x, model(xx).detach().numpy(), label='polynom')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
