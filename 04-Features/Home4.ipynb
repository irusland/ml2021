{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from numpy.testing import assert_array_equal, assert_array_almost_equal, assert_equal, assert_almost_equal\n",
    "from pandas.testing import assert_frame_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Основы метрик классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На вход подаются 2 массива: \n",
    "\n",
    "* $y_{real}$ - реальные значения бинарных классов\n",
    "* $y_{pred}$ - предсказанные значения бинарных классов. \n",
    "\n",
    "Вам необходимо посчитать, **не используя** стандартные функции, метрики: \n",
    "\n",
    "* $accuracy$\n",
    "* $precision$\n",
    "* $recall$\n",
    "* $F_1$\n",
    "\n",
    "Возвращать числа нужно именно в данном порядке.\n",
    "\n",
    "### Sample 1\n",
    "#### Input:\n",
    "```python\n",
    "y_real = np.array([0, 1, 0, 0, 1, 1, 1, 1])\n",
    "y_pred = np.array([0, 1, 1, 0, 1, 1, 0, 0])\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "0.625, 0.75, 0.6, 0.66\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def main_metrics(y_real: np.array, y_pred: np.array) -> (float, float, float, float):\n",
    "    acc = np.mean(y_real==y_pred)\n",
    "    pre = (y_real*y_pred==1).sum() / len(y_real)\n",
    "    rec = None\n",
    "    f1 = None\n",
    "    return (acc, pre, rec, f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "(0.375, 0.75, -0.375)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-5d6292d38cd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m  \u001b[0;34m-\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: (0.375, 0.75, -0.375)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "######################################################\n",
    "y_real = np.array([0, 1, 0, 0, 1, 1, 1, 1])\n",
    "y_pred = np.array([0, 1, 1, 0, 1, 1, 0, 0])\n",
    "\n",
    "\n",
    "acc, pre, rec, f1 = main_metrics(y_real, y_pred)\n",
    "\n",
    "assert np.abs(acc - accuracy_score(y_real, y_pred)) < 0.001\n",
    "assert np.abs(pre - precision_score(y_real, y_pred)) < 0.001, (pre, precision_score(y_real, y_pred), pre- precision_score(y_real, y_pred) )\n",
    "assert np.abs(rec - recall_score(y_real, y_pred)) < 0.001\n",
    "assert np.abs(f1  - f1_score(y_real, y_pred)) < 0.001\n",
    "######################################################\n",
    "y_real = np.random.choice(2, 1000)\n",
    "y_pred = np.random.choice(2, 1000)\n",
    "\n",
    "acc, pre, rec, f1 = main_metrics(y_real, y_pred)\n",
    "\n",
    "assert np.abs(acc - accuracy_score(y_real, y_pred)) < 0.001\n",
    "assert np.abs(pre - precision_score(y_real, y_pred)) < 0.001\n",
    "assert np.abs(rec - recall_score(y_real, y_pred)) < 0.001\n",
    "assert np.abs(f1  - f1_score(y_real, y_pred)) < 0.001\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Основы метрик регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решаем задачу регрессии. На вход подаются 2 массива: $y_{real}$ - реальные значения функции и $y_{pred}$ - предсказанные значения функции. \n",
    "\n",
    "Вам необходимо посчитать, **не используя** стандартные функции, метрики: \n",
    "\n",
    "* $R^2score$\n",
    "* $MAE$ - `mean_absolute_error`\n",
    "* $MSE$ - `mean_squared_error`\n",
    "* $MSLE$ - `mean_squared_log_error`\n",
    "\n",
    "Возвращать числа нужно именно в данном порядке.\n",
    "\n",
    "Можете сверяться с реальными метриками в `sklearn.metrics`.\n",
    "\n",
    "Все числа в тестах больше 0, поэтому $MSLE$ будет считаться корректно.\n",
    "### Sample 1\n",
    "#### Input:\n",
    "```python\n",
    "y_real = np.array([1, 2, 3, 4, 6])\n",
    "y_pred = np.array([1, 3, 2, 4, 5])\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "0.797297, 0.6, 0.6, 0.037856\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def reg_metrics(y_real: np.array, y_pred: np.array) -> (float, float, float, float):\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score as R2, mean_absolute_error as MAE, mean_squared_log_error as MSLE, mean_squared_error as MSE \n",
    "######################################################\n",
    "y_real = np.array([1,2,3,4,6])\n",
    "y_pred = np.array([1,3,2,4,5])\n",
    "\n",
    "\n",
    "r2, mae, mse, msle = reg_metrics(y_real, y_pred)\n",
    "\n",
    "assert np.abs(r2 - R2(y_real, y_pred)) < 0.001\n",
    "assert np.abs(mae - MAE(y_real, y_pred)) < 0.001\n",
    "assert np.abs(mse - MSE(y_real, y_pred)) < 0.001\n",
    "assert np.abs(msle  - MSLE(y_real, y_pred)) < 0.001\n",
    "######################################################\n",
    "y_real = np.random.choice(1000, 1000)\n",
    "y_pred = np.random.choice(1000, 1000)\n",
    "\n",
    "r2, mae, mse, msle = reg_metrics(y_real, y_pred)\n",
    "\n",
    "assert np.abs(r2 - R2(y_real, y_pred)) < 0.001\n",
    "assert np.abs(mae - MAE(y_real, y_pred)) < 0.001\n",
    "assert np.abs(mse - MSE(y_real, y_pred)) < 0.001\n",
    "assert np.abs(msle  - MSLE(y_real, y_pred)) < 0.001\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Нахождение Roc-curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам на вход даны $y_{real}$ и массив вероятностей $y_{prob} = P(y_{pred}=1)$ необходимо реализовать функцию `roc-curve`, которая вернет 2 массива различных значений $fpr$ и $tpr$, для дальнейшего построения $Roc$ кривой.\n",
    "\n",
    "Можно считать, что все вероятности ограничены $decimal=2$ (у каждого числа не более 2-х знаков после запятой).\n",
    "\n",
    "### Sample\n",
    "#### Input:\n",
    "```python\n",
    "y_real = np.array([  1,   1,   0,   0,   0,   1,   0,   1,   0])\n",
    "y_prob = np.array([0.8, 0.8, 0.2, 0.2, 0.6, 0.4, 0.6, 0.6, 0.4])\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "array([0.,  0.,  0.4, 0.6, 1. ]), #fpr\n",
    "array([0., 0.5, 0.75,  1., 1. ])  #tpr\n",
    "```\n",
    "\n",
    "### Sample 2\n",
    "#### Input:\n",
    "```python\n",
    "y_real = np.array([  1,   1,   0,   0,   1,   0,   1,   0])\n",
    "y_prob = np.array([0.8, 0.8, 0.2, 0.2, 0.4, 0.4, 0.6, 0.6])\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "array([0.,  0., 0.25, 0.5, 1. ]), #fpr\n",
    "array([0., 0.5, 0.75,  1., 1. ])  #tpr\n",
    "\n",
    "или \n",
    "\n",
    "array([0.,  0., 0.5, 1. ]), #fpr\n",
    "array([0., 0.5,  1., 1. ])  #tpr\n",
    "```\n",
    "\n",
    "Обратите внимание на 2 пример: roc кривая, которая задается ими - одинаковая. Точка, которая уходит, находится на прямой между двумя соседними, в целом такие точки можно убирать, но будут приниматься оба варианта. Функция `sklearn.metrics.roc_curve` возвращает второй вариант."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def roc(y_real: np.array, y_prob: np.array) -> (np.array, np.array):\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, roc_curve\n",
    "######################################################\n",
    "y_real = np.array([  1,   1,   0,   0,   0,   1,   0,   1,   0])\n",
    "y_prob = np.array([0.8, 0.8, 0.2, 0.2, 0.6, 0.4, 0.6, 0.6, 0.4])\n",
    "fpr_true, tpr_true, _ = roc_curve(y_real, y_prob)\n",
    "fpr, tpr = roc(y_real, y_prob)\n",
    "\n",
    "assert auc(fpr, tpr) - auc(fpr_true, tpr_true) < 0.01\n",
    "######################################################\n",
    "y_real = np.array([  1,   1,   0,   0,   1,   0,   1,   0])\n",
    "y_prob = np.array([0.8, 0.8, 0.2, 0.2, 0.4, 0.4, 0.6, 0.6])\n",
    "fpr_true, tpr_true, _  = roc_curve(y_real, y_prob)\n",
    "fpr, tpr = roc(y_real, y_prob)\n",
    "\n",
    "assert auc(fpr, tpr) - auc(fpr_true, tpr_true) < 0.01\n",
    "######################################################\n",
    "y_real = np.random.choice(2, 1000) \n",
    "y_prob = np.random.choice(101, 1000) / 100\n",
    "\n",
    "fpr_true, tpr_true, _  = roc_curve(y_real, y_prob)\n",
    "fpr, tpr = roc(y_real, y_prob)\n",
    "\n",
    "assert auc(fpr, tpr) - auc(fpr_true, tpr_true) < 0.01\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C помощью [GridSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) найдите лучшие коэффициенты гиперпараметров `max_depth` и `min_samples_leaf` для классификатора [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) и верните обученный grid_search. \n",
    "\n",
    "* Пределы `max_depth` $(1, 10)$ \n",
    "* Пределы `min_samples_leaf` $(1, 10)$  \n",
    "* Входные данные в `data/sonar.csv`\n",
    "* scoring - `precision`\n",
    "* cv - $5$\n",
    "* Другие параметры в `DecisionTreeClassifier` не указывать.\n",
    "\n",
    "Не нужно Shuffl-ить данные, это может повлиять на ответ и в итоге задача не зачтется."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def fit_gs(X: np.ndarray, y: np.ndarray) ->  GridSearchCV:\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('data/sonar.csv').drop(columns=['y']).values\n",
    "Y = pd.read_csv('data/sonar.csv')['y']\n",
    "######################################################\n",
    "gs = fit_gs(X,Y)\n",
    "\n",
    "assert gs.best_params_['max_depth'] == 4\n",
    "assert gs.best_params_['min_samples_leaf'] == 3\n",
    "assert np.abs(gs.best_score_ - 0.7829244) < 0.001\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Удаление Nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Серия задач в данном модуле объединена в одну [большую задачу по предсказанию данных](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview). В ходе выполнения модуля мы будем разбирать определенные техники, которые нужны для ее решения. Настоятельно рекомендуем выполнить все шаги **по порядку**, тогда в конце вы получите решение большой реальной задачи по МЛ.\n",
    "\n",
    "Нам даны [данные](https://yadi.sk/d/tcElz6cqSNpPqA) о домах выставленных на продажу. Нам необходимо решить задачу регрессии и предсказать цену продажи дома для $X_{test}$ по данным $X_{train}$ и $y_{train}$. В нашем случае  $y_{train}$ - это столбик `SalePrice`, $X_{train}$ - все остальные столбики.\n",
    "\n",
    "На вход подается 2 считанных датафрейма **df_train**, **df_test** из файлов без изменений. \n",
    "\n",
    "Начальная подготовка:\n",
    "\n",
    "* Разделить **df_train** на **X_train**(`pd.Dataframe`) и **y_train**(`pd.Series`).\n",
    "* Сконкатенировать **X_train** и **df_test** в **df** по вертикали (можно ориентироваться по столбику `Id` они как раз идут по-порядку). Не забудьте обновить индекс!\n",
    "\n",
    "Задачи:\n",
    "\n",
    "* Заменить в **df** все Nan-ы в категориальных признаках (`object`) на строку `missing`\n",
    "* Заменить в **df** все Nan-ы в числовых признаках на 0.\n",
    "\n",
    "Вернуть из функции измененный **df**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def del_nan(df_train: pd.DataFrame, df_test: pd.DataFrame) -> pd.DataFrame:\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "del_nan_df = pd.read_csv('data/del_nan.csv')\n",
    "######################################################\n",
    "assert_frame_equal(del_nan(train, test), del_nan_df)\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Порядковые категории"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам на вход приходит **df** из предыдущей задачи.\n",
    "\n",
    "Если внимательно изучить файл `data_description` можно понять, что многие категориальные признаки - порядковые (упорядоченное множество). Значит их можно перевести в осмысленные числа. Значит тут можно воспользоваться `LabelEncoding`.\n",
    "\n",
    "Ваша задача: заменить в **df** категориальные признаки на числовые, для порядковых признаков.\n",
    "\n",
    "На выходе возвращаем измененный **df**.\n",
    "\n",
    "Чтобы слегка упростить вам жизнь, вот вам готовые словари для перевода. Однако к каким столбцам их применять - вы должны выяснить сами, изучив файл `data_description`. Каждый маппинг используется хотя бы 1 раз, а некоторые и не по одному разу.\n",
    "\n",
    "```python\n",
    "{'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'missing':0}\n",
    "{'Gd':4, 'Av': 3, 'Mn': 2, 'No': 1, 'missing': 0}\n",
    "{'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, 'missing': 0}\n",
    "{'Typ': 8, 'Min1': 7, 'Min2': 6, 'Mod': 5, 'Maj1': 4, 'Maj2': 3, 'Sev': 2, 'Sal': 1, 'missing': 0}\n",
    "{'Fin': 3, 'RFn': 2, 'Unf': 1, 'missing': 0}\n",
    "{'GdPrv': 4, 'MnPrv': 3, 'GdWo': 2, 'MnWw': 1, 'missing': 0}\n",
    "{'Reg': 4, 'IR1': 3, 'IR2': 2, 'IR3': 1, 'missing': 0}\n",
    "{'Lvl': 4, 'Bnk': 3, 'HLS':2,'Low':1, 'missing': 0}\n",
    "{'AllPub':4, 'NoSewr':3, 'NoSeWa':2, 'ELO':1, 'missing':0}\n",
    "{'Gtl':3, 'Mod':2, 'Sev':1, 'missing':0}\n",
    "{'SBrkr':5, 'FuseA':4, 'FuseF':3, 'FuseP':2, 'Mix':1, 'missing':0}\n",
    "{'Y':3, 'P':2, 'N':1, 'missing':0}\n",
    "{'Y':1, 'N':0, 'missing':0} #тут нет ошибки, все так и задумано:)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hint\n",
    "После перевода у вас должно **остаться** 20 категориальных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def cat_to_num(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_nan_df = pd.read_csv('data/del_nan.csv')\n",
    "answer = pd.read_csv('data/cat_to_num.csv')\n",
    "######################################################\n",
    "cat_to_num_df = cat_to_num(del_nan_df)\n",
    "assert_frame_equal(cat_to_num_df, answer)\n",
    "\n",
    "categorical_cols = [col for col in cat_to_num_df.columns if cat_to_num_df[col].dtypes == \"object\"]\n",
    "assert len(categorical_cols) == 20\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. One hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь разберемся с непорядковыми категориальными признаками.\n",
    "\n",
    "Для начала заметим признак `MSSubClass`, у которого тип `int64`, но если посмотреть в описание `data_description` можно понять, что это - категориальный признак. \n",
    "\n",
    "* Измените тип признака `MSSubClass` с `int64` на `object`\n",
    "\n",
    "Теперь можно сделать `One hot encoding`:\n",
    "\n",
    "* Найдите все колонки с категориальными признаками и составьте из них отдельный **df_oh** `pd.DataFrame` (индекс сохранить прежний)\n",
    "* Применить к полученному фрейму **df_oh** функцию [`pd.get_dummies`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) (Реализует `One Hot Encoding`)\n",
    "* Удалить категориальные колонки из **df** и добавить справа к **df** фрейм с `One Hot Encoding`\n",
    " \n",
    "Вернуть из функции **df**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hint\n",
    "Итого должно получится 238 колонка из них 179 пришли из `One hot encoding` фрейма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def one_hot(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_to_num_df = pd.read_csv('data/cat_to_num.csv')\n",
    "one_hot_ans = pd.read_csv('data/one_hot.csv')\n",
    "######################################################\n",
    "one_hot_df = one_hot(cat_to_num_df)\n",
    "assert_frame_equal(one_hot_df.astype('float64').reindex(sorted(one_hot_df.columns), axis=1), \n",
    "                   one_hot_ans.astype('float64').reindex(sorted(one_hot_ans.columns), axis=1))\n",
    "\n",
    "assert one_hot_df.shape[1] == 238\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Некоррелирующие признаки "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы разобрались с категориальными признаками, теперь разберемся с числовыми.\n",
    "Для числовых признаков можно посчитать корреляцию с правильным ответом. Если признаки слабо коррелируют, то они нам не нужны. Например колонка `Id` явно никак не влияет на стоимость дома.\n",
    "\n",
    "Вам на вход передается изначальный **df_train** и **df** полученный из предыдущей задачи.\n",
    "\n",
    "Ваша задача: \n",
    "\n",
    "* найти корреляцию всех **числовых** признаков **df_train** с признаком `SalePrice` с помощью `pd.corr`\n",
    "* если абсолютное значение корреляции признака с `SalePrice` меньше $0.05$ - удалите этот признак из **df**\n",
    "\n",
    "Верните измененный **df** и столбец корреляции признаков с признаком `SalePrice` упорядоченный по убыванию. Начало столбца корреляции выглядит следующим образом:\n",
    "\n",
    "|               |SalePrice |\n",
    "|---------------|----------|\n",
    "|**SalePrice**  |1.000000  |\n",
    "|**OverallQual**|0.790982  |\n",
    "|**GrLivArea**  |0.708624  |\n",
    "|**GarageCars** |0.640409  |\n",
    "|**GarageArea** |0.623431  |\n",
    "|**TotalBsmtSF**|0.613581  |\n",
    "|**1stFlrSF**   |0.605852  |\n",
    "|**FullBath**   |0.560664  |\n",
    "\n",
    "Всего должно получиться 37 числовых признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(df: pd.DataFrame, df_train: pd.DataFrame) -> (pd.DataFrame, pd.DataFrame):\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_df = pd.read_csv('data/one_hot.csv')\n",
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "ans_corr_df = pd.read_csv('data/corr_df.csv')\n",
    "ans_corr = pd.read_csv('data/corr.csv').set_index('Unnamed: 0')\n",
    "######################################################\n",
    "corr_df, corr = correlation(one_hot_df, df_train)\n",
    "\n",
    "assert_frame_equal(corr_df.astype('float64').reindex(sorted(corr_df.columns), axis=1),\n",
    "                   ans_corr_df.astype('float64').reindex(sorted(ans_corr_df.columns), axis=1))\n",
    "\n",
    "assert_array_almost_equal(corr.values, ans_corr.values, decimal=4)\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Feature Engineering и Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу 2 простые задачки:\n",
    "\n",
    "1) Давайте нагенерируем несколько фич во входном фрейме **df**:\n",
    "\n",
    "    * `TotalArea` = `TotalBsmtSF` + `1stFlrSF` + `2ndFlrSF` + `GrLivArea` + `GarageArea`\n",
    "    * `YearAverage` = (`YearRemodAdd` + `YearBuilt`) / 2\n",
    "    * `LiveAreaQual` = `OverallQual` * `GrLivArea`\n",
    "\n",
    "    На выход отправьте **df** c тремя новымим столбиками. столбцы должны идти в том же порядки что указаны в списке в хвосте **df**.\n",
    "\n",
    "2) У стандартного и нормального масштабирования есть одна проблема: она учитывает все признаки, даже те, которые изначально некорректны (шум, выбросы). Чтобы избавитьться от шумов и выбросов и корректно масштабировать выборку необходимо использовать [RobustScaling](https://scikit-learn.org/0.18/auto_examples/preprocessing/plot_robust_scaling.html).\n",
    "\n",
    "    Ваша задача - отмасштабировать полученный фрейм с помощью `RobustScaler`. И вернуть отмасштабированный массив (да, скалирование возвращает массив, а не DataFrame)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def feature_en(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass\n",
    "\n",
    "def scaling(df: pd.DataFrame) -> np.array:\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = pd.read_csv('data/corr_df.csv')\n",
    "ans_feature_df = pd.read_csv('data/feature_df.csv')\n",
    "######################################################\n",
    "\n",
    "feature_df = feature_en(corr_df)\n",
    "\n",
    "assert_frame_equal(feature_df.astype('float64').reindex(sorted(feature_df.columns), axis=1),\n",
    "                   ans_feature_df.astype('float64').reindex(sorted(ans_feature_df.columns), axis=1))\n",
    "######################################################\n",
    "feature_df = pd.read_csv('data/feature_df.csv')\n",
    "ans_scale_df = pd.read_csv('data/scale_df.csv').values\n",
    "######################################################\n",
    "\n",
    "scale_df = scaling(feature_df)\n",
    "\n",
    "assert_array_almost_equal(scale_df,\n",
    "                          ans_scale_df,\n",
    "                          decimal=6)\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Смешанная модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, теперь мы готовы обучать модель! Осталось изучить последний интересный трюк - смешанные модели.\n",
    "\n",
    "Возьмем [2 регрессии](https://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b):\n",
    "\n",
    "* Ridge\n",
    "* Lasso\n",
    " \n",
    "Найдем оптимальные значения $\\alpha$ для обеих регрессий с помощью GridSearch.\n",
    "\n",
    "Теперь отправим обе модели с наилучшими параметрами в класс указанный снизу. Это класс смешения моделей. В нем параметр $\\beta \\in [0,1]$ - это коэффициент, с которым берется ответ одного классификаторв, а ответ второго - с коэффициентом $(1 - \\beta)$. Такая техника нередко позволяет добиться лучших результатов, чем одна модель.\n",
    "\n",
    "Теперь найдем наилучшее $\\beta$ для смешенной модели также с помощью GridSearch. Осталось получить **y_pred** с помощью наилучшей смешанной модели.\n",
    "\n",
    "На вход вы получаете **X_scaled** из предыдущей задачи и **df_train** начальный. Мы подготовили за вас **X_train**, **y_train** и **X_test**. \n",
    "\n",
    "В задаче необходимо минимизировать метрику `neg_mean_squared_log_error`. Для удобства мы возьмем `np.log1p(y_train)` и будем минимизировать метрику `neg_mean_squared_error`. Эту метрику необходимо минимизировать у всех 3-х GridSearch.\n",
    "\n",
    "На выход отправьте GridSearch объект смешанной модели, а также результат **y_test**. (Не забудьте его проэкспоненциировать).\n",
    "\n",
    "Мы выдаем вам ориентировачные параметры для каждого GridSearch. Вы можете увеличить перебор, чтобы получить лучшую модель.\n",
    "```python\n",
    "params_ridge = {'alpha': np.arange(1, 20)}\n",
    "params_lasso = {'alpha': np.logspace(-4, 3, num=8, base=10)}\n",
    "params_blend = {'beta': np.linspace(0, 1, 11)}\n",
    "```\n",
    "\n",
    "Первые 2 GridSearch **не нужно** писать в функции: они могут работать достаточно долго и превысят лимит работы задачи на сервере. Найдите у себя локально наилучшие параметры и уже с этими параметрами создайте смешанную модель внутри функции. \n",
    "\n",
    "Также не нужно сильно увеличивать перебор для $\\beta$ - того, что есть, более чем достаточно.\n",
    "\n",
    "P.S. Осталось сохранить файл с **y_test** и отправить его в [соревнование](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/submit). \n",
    "\n",
    "Улучшайте свои результы пробуя другие модели и другие параметры. Уберите больше ненужных признаков, добавьте новые фичи. Экспериментируйте и дерзайте!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "class BlendRegressor(BaseEstimator): # предок класса классификаторов, чтобы можно было засунуть в GridSearch\n",
    "    def __init__(self, clf1, clf2, beta=0.5):\n",
    "        self.clf1 = clf1 \n",
    "        self.clf2 = clf2\n",
    "        self.beta = beta #параметр смешивания\n",
    "\n",
    "    def fit(self, X, y): #обучаем классификатор\n",
    "        self.X_ = X\n",
    "        self.y_ = y \n",
    "        self.clf1.fit(X, y)\n",
    "        self.clf2.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X): #возвращаем значения \n",
    "        return self.clf1.predict(X) * self.beta + self.clf2.predict(X) * (1 - self.beta)\n",
    "\n",
    "    \n",
    "def learning(X_scaled: np.array, df_train: pd.DataFrame) -> (GridSearchCV, np.array):\n",
    "    X_train = X_scaled[0: len(df_train),]\n",
    "    X_test  = X_scaled[len(df_train): len(X_scaled)]\n",
    "    y_train = np.log1p(df_train['SalePrice'])\n",
    "    \n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    \n",
    "    return blend_gs, np.exp(y_test) - 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
