{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from numpy.testing import assert_array_equal, assert_array_almost_equal, assert_equal, assert_almost_equal\n",
    "from pandas.testing import assert_frame_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Основы метрик классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На вход подаются 2 массива: \n",
    "\n",
    "* $y_{real}$ - реальные значения бинарных классов\n",
    "* $y_{pred}$ - предсказанные значения бинарных классов. \n",
    "\n",
    "Вам необходимо посчитать, **не используя** стандартные функции, метрики: \n",
    "\n",
    "* $accuracy$\n",
    "* $precision$\n",
    "* $recall$\n",
    "* $F_1$\n",
    "\n",
    "Возвращать числа нужно именно в данном порядке.\n",
    "\n",
    "### Sample 1\n",
    "#### Input:\n",
    "```python\n",
    "y_real = np.array([0, 1, 0, 0, 1, 1, 1, 1])\n",
    "y_pred = np.array([0, 1, 1, 0, 1, 1, 0, 0])\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "0.625, 0.75, 0.6, 0.66\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def main_metrics(y_real: np.array, y_pred: np.array) -> (float, float, float, float):\n",
    "    acc = np.mean(y_real==y_pred)\n",
    "    tp = (y_real*y_pred).sum() # true positive\n",
    "    fn = (y_real * (y_pred ^ y_real)).sum() # false negative\n",
    "    fp = (y_pred * (y_pred ^ y_real)).sum()\n",
    "    tn = ((1 - y_real) * (1 - y_pred)).sum()\n",
    "    \n",
    "    \n",
    "    pre = tp / (fp + tp)\n",
    "    rec = tp / (fn + tp)\n",
    "    f1 = 2 * pre * rec / (pre + rec)\n",
    "    return (acc, pre, rec, f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOLUTION ALTERNATIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def perf_measure(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "           TP += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "           TN += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)\n",
    "\n",
    "\n",
    "def main_metrics(y_real: np.array, y_pred: np.array) -> (float, float, float, float):\n",
    "    acc = np.mean(y_real==y_pred)\n",
    "    TP, FP, TN, FN = perf_measure(y_real, y_pred)\n",
    "    pre = TP / (FP + TP)\n",
    "    rec = TP / (FN + TP)\n",
    "    f1 = 2 * pre * rec / (pre + rec)\n",
    "    return (acc, pre, rec, f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "######################################################\n",
    "y_real = np.array([0, 1, 0, 0, 1, 1, 1, 1])\n",
    "y_pred = np.array([0, 1, 1, 0, 1, 1, 0, 0])\n",
    "\n",
    "\n",
    "acc, pre, rec, f1 = main_metrics(y_real, y_pred)\n",
    "\n",
    "assert np.abs(acc - accuracy_score(y_real, y_pred)) < 0.001\n",
    "assert np.abs(pre - precision_score(y_real, y_pred)) < 0.001, (pre, precision_score(y_real, y_pred), pre- precision_score(y_real, y_pred) )\n",
    "assert np.abs(rec - recall_score(y_real, y_pred)) < 0.001\n",
    "assert np.abs(f1  - f1_score(y_real, y_pred)) < 0.001\n",
    "######################################################\n",
    "y_real = np.random.choice(2, 1000)\n",
    "y_pred = np.random.choice(2, 1000)\n",
    "\n",
    "acc, pre, rec, f1 = main_metrics(y_real, y_pred)\n",
    "\n",
    "assert np.abs(acc - accuracy_score(y_real, y_pred)) < 0.001\n",
    "assert np.abs(pre - precision_score(y_real, y_pred)) < 0.001\n",
    "assert np.abs(rec - recall_score(y_real, y_pred)) < 0.001\n",
    "assert np.abs(f1  - f1_score(y_real, y_pred)) < 0.001\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Основы метрик регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решаем задачу регрессии. На вход подаются 2 массива: $y_{real}$ - реальные значения функции и $y_{pred}$ - предсказанные значения функции. \n",
    "\n",
    "Вам необходимо посчитать, **не используя** стандартные функции, метрики: \n",
    "\n",
    "* $R^2score$\n",
    "* $MAE$ - `mean_absolute_error`\n",
    "* $MSE$ - `mean_squared_error`\n",
    "* $MSLE$ - `mean_squared_log_error`\n",
    "\n",
    "Возвращать числа нужно именно в данном порядке.\n",
    "\n",
    "Можете сверяться с реальными метриками в `sklearn.metrics`.\n",
    "\n",
    "Все числа в тестах больше 0, поэтому $MSLE$ будет считаться корректно.\n",
    "### Sample 1\n",
    "#### Input:\n",
    "```python\n",
    "y_real = np.array([1, 2, 3, 4, 6])\n",
    "y_pred = np.array([1, 3, 2, 4, 5])\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "0.797297, 0.6, 0.6, 0.037856\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def reg_metrics(x: np.array, y: np.array) -> (float, float, float, float):\n",
    "    r2 = 1 - ((x - y) ** 2).sum() / ((x - np.mean(x)) ** 2).sum()\n",
    "    mae = np.mean(np.abs(x - y))\n",
    "    mse = ((x - y) * (x - y)).sum() / len(x)\n",
    "    a = np.log(x + 1) - np.log(y + 1)\n",
    "    msle = (a * a).sum() / len(x)\n",
    "    return r2, mae, mse, msle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score as R2, mean_absolute_error as MAE, mean_squared_log_error as MSLE, mean_squared_error as MSE \n",
    "######################################################\n",
    "y_real = np.array([1,2,3,4,6])\n",
    "y_pred = np.array([1,3,2,4,5])\n",
    "\n",
    "\n",
    "r2, mae, mse, msle = reg_metrics(y_real, y_pred)\n",
    "\n",
    "assert np.abs(r2 - R2(y_real, y_pred)) < 0.001\n",
    "assert np.abs(mae - MAE(y_real, y_pred)) < 0.001\n",
    "assert np.abs(mse - MSE(y_real, y_pred)) < 0.001\n",
    "assert np.abs(msle  - MSLE(y_real, y_pred)) < 0.001\n",
    "######################################################\n",
    "y_real = np.random.choice(1000, 1000)\n",
    "y_pred = np.random.choice(1000, 1000)\n",
    "\n",
    "r2, mae, mse, msle = reg_metrics(y_real, y_pred)\n",
    "\n",
    "assert np.abs(r2 - R2(y_real, y_pred)) < 0.001\n",
    "assert np.abs(mae - MAE(y_real, y_pred)) < 0.001\n",
    "assert np.abs(mse - MSE(y_real, y_pred)) < 0.001\n",
    "assert np.abs(msle  - MSLE(y_real, y_pred)) < 0.001\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Нахождение Roc-curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам на вход даны $y_{real}$ и массив вероятностей $y_{prob} = P(y_{pred}=1)$ необходимо реализовать функцию `roc-curve`, которая вернет 2 массива различных значений $fpr$ и $tpr$, для дальнейшего построения $Roc$ кривой.\n",
    "\n",
    "Можно считать, что все вероятности ограничены $decimal=2$ (у каждого числа не более 2-х знаков после запятой).\n",
    "\n",
    "### Sample\n",
    "#### Input:\n",
    "```python\n",
    "y_real = np.array([  1,   1,   0,   0,   0,   1,   0,   1,   0])\n",
    "y_prob = np.array([0.8, 0.8, 0.2, 0.2, 0.6, 0.4, 0.6, 0.6, 0.4])\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "array([0.,  0.,  0.4, 0.6, 1. ]), #fpr\n",
    "array([0., 0.5, 0.75,  1., 1. ])  #tpr\n",
    "```\n",
    "\n",
    "### Sample 2\n",
    "#### Input:\n",
    "```python\n",
    "y_real = np.array([  1,   1,   0,   0,   1,   0,   1,   0])\n",
    "y_prob = np.array([0.8, 0.8, 0.2, 0.2, 0.4, 0.4, 0.6, 0.6])\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "array([0.,  0., 0.25, 0.5, 1. ]), #fpr\n",
    "array([0., 0.5, 0.75,  1., 1. ])  #tpr\n",
    "\n",
    "или \n",
    "\n",
    "array([0.,  0., 0.5, 1. ]), #fpr\n",
    "array([0., 0.5,  1., 1. ])  #tpr\n",
    "```\n",
    "\n",
    "Обратите внимание на 2 пример: roc кривая, которая задается ими - одинаковая. Точка, которая уходит, находится на прямой между двумя соседними, в целом такие точки можно убирать, но будут приниматься оба варианта. Функция `sklearn.metrics.roc_curve` возвращает второй вариант."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "def roc(y_real: np.array, y_prob: np.array) -> (np.array, np.array):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_real, y_prob, pos_label=None)\n",
    "    print(fpr, tpr, sep='\\n')\n",
    "    return     fpr, tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.  0.4 0.6 1. ]\n",
      "[0.   0.5  0.75 1.   1.  ]\n",
      "[0.  0.  0.5 1. ]\n",
      "[0.  0.5 1.  1. ]\n",
      "[0.         0.00796813 0.02390438 0.03386454 0.03984064 0.04581673\n",
      " 0.05179283 0.05976096 0.07171315 0.07968127 0.09561753 0.10358566\n",
      " 0.11155378 0.11952191 0.12749004 0.13346614 0.14940239 0.15737052\n",
      " 0.17131474 0.187251   0.20119522 0.21115538 0.22310757 0.23705179\n",
      " 0.24900398 0.25697211 0.26294821 0.27290837 0.27689243 0.29282869\n",
      " 0.29880478 0.31474104 0.31673307 0.32270916 0.32868526 0.33864542\n",
      " 0.35059761 0.36055777 0.37051793 0.38247012 0.39043825 0.40039841\n",
      " 0.41035857 0.42231076 0.42828685 0.43625498 0.4501992  0.4561753\n",
      " 0.46613546 0.48007968 0.49203187 0.5059761  0.51792829 0.52390438\n",
      " 0.53386454 0.55179283 0.56175299 0.57171315 0.58565737 0.59561753\n",
      " 0.60756972 0.61752988 0.62749004 0.63545817 0.64741036 0.65338645\n",
      " 0.66135458 0.67131474 0.67928287 0.69322709 0.69721116 0.70916335\n",
      " 0.71912351 0.72709163 0.73705179 0.74103586 0.75099602 0.75896414\n",
      " 0.7689243  0.77290837 0.79083665 0.81075697 0.82270916 0.83665339\n",
      " 0.85059761 0.85657371 0.86653386 0.87848606 0.88446215 0.89641434\n",
      " 0.90039841 0.91035857 0.91434263 0.93227092 0.94023904 0.95219124\n",
      " 0.96215139 0.96812749 0.97609562 0.99203187 1.        ]\n",
      "[0.         0.00401606 0.02208835 0.03012048 0.04016064 0.04618474\n",
      " 0.0562249  0.06827309 0.07630522 0.08232932 0.08835341 0.10040161\n",
      " 0.1064257  0.11445783 0.12048193 0.13253012 0.15261044 0.16064257\n",
      " 0.1746988  0.18674699 0.19678715 0.21084337 0.2188755  0.22891566\n",
      " 0.25502008 0.25903614 0.26104418 0.27108434 0.2751004  0.28514056\n",
      " 0.29718876 0.31526104 0.3253012  0.33333333 0.33935743 0.35341365\n",
      " 0.36345382 0.37349398 0.38955823 0.39558233 0.40160643 0.40963855\n",
      " 0.41967871 0.42771084 0.44176707 0.44779116 0.45783133 0.46987952\n",
      " 0.47590361 0.47991968 0.4939759  0.50200803 0.51405622 0.52008032\n",
      " 0.53212851 0.54216867 0.55421687 0.562249   0.57228916 0.57831325\n",
      " 0.58433735 0.59036145 0.59839357 0.60441767 0.61646586 0.62650602\n",
      " 0.63855422 0.65060241 0.6746988  0.68875502 0.69678715 0.70481928\n",
      " 0.70883534 0.72690763 0.74497992 0.75301205 0.76104418 0.76907631\n",
      " 0.7811245  0.79718876 0.80522088 0.80923695 0.81726908 0.82128514\n",
      " 0.83333333 0.84538153 0.85140562 0.86144578 0.86546185 0.87349398\n",
      " 0.88353414 0.89558233 0.90763052 0.92168675 0.93574297 0.9497992\n",
      " 0.96184739 0.96987952 0.97590361 0.98995984 1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import auc, roc_curve\n",
    "######################################################\n",
    "y_real = np.array([  1,   1,   0,   0,   0,   1,   0,   1,   0])\n",
    "y_prob = np.array([0.8, 0.8, 0.2, 0.2, 0.6, 0.4, 0.6, 0.6, 0.4])\n",
    "fpr_true, tpr_true, _ = roc_curve(y_real, y_prob)\n",
    "fpr, tpr = roc(y_real, y_prob)\n",
    "\n",
    "assert auc(fpr, tpr) - auc(fpr_true, tpr_true) < 0.01\n",
    "######################################################\n",
    "y_real = np.array([  1,   1,   0,   0,   1,   0,   1,   0])\n",
    "y_prob = np.array([0.8, 0.8, 0.2, 0.2, 0.4, 0.4, 0.6, 0.6])\n",
    "fpr_true, tpr_true, _  = roc_curve(y_real, y_prob)\n",
    "fpr, tpr = roc(y_real, y_prob)\n",
    "\n",
    "assert auc(fpr, tpr) - auc(fpr_true, tpr_true) < 0.01\n",
    "######################################################\n",
    "y_real = np.random.choice(2, 1000) \n",
    "y_prob = np.random.choice(101, 1000) / 100\n",
    "\n",
    "fpr_true, tpr_true, _  = roc_curve(y_real, y_prob)\n",
    "fpr, tpr = roc(y_real, y_prob)\n",
    "\n",
    "assert auc(fpr, tpr) - auc(fpr_true, tpr_true) < 0.01\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C помощью [GridSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) найдите лучшие коэффициенты гиперпараметров `max_depth` и `min_samples_leaf` для классификатора [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) и верните обученный grid_search. \n",
    "\n",
    "* Пределы `max_depth` $(1, 10)$ \n",
    "* Пределы `min_samples_leaf` $(1, 10)$  \n",
    "* Входные данные в `data/sonar.csv`\n",
    "* scoring - `precision`\n",
    "* cv - $5$\n",
    "* Другие параметры в `DecisionTreeClassifier` не указывать.\n",
    "\n",
    "Не нужно Shuffl-ить данные, это может повлиять на ответ и в итоге задача не зачтется."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def fit_gs(X: np.ndarray, y: np.ndarray) ->  GridSearchCV:\n",
    "    dt = DecisionTreeClassifier(\n",
    "        max_depth=3,\n",
    "        min_samples_leaf=3,\n",
    "\n",
    "    )\n",
    "    params = {'max_depth': list(range(2, 100)), 'min_samples_leaf': [2, 3, 4]}\n",
    "    gs = GridSearchCV(\n",
    "        estimator=dt, \n",
    "        param_grid=params, \n",
    "        cv=5, \n",
    "        scoring='precision')\n",
    "    gs.fit(X, y)\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 4, 'min_samples_leaf': 3}\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv('data/sonar.csv').drop(columns=['y']).values\n",
    "Y = pd.read_csv('data/sonar.csv')['y']\n",
    "######################################################\n",
    "gs = fit_gs(X,Y)\n",
    "\n",
    "print(gs.best_params_)\n",
    "\n",
    "assert gs.best_params_['max_depth'] == 4\n",
    "assert gs.best_params_['min_samples_leaf'] == 3\n",
    "assert np.abs(gs.best_score_ - 0.7829244) < 0.001\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Удаление Nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Серия задач в данном модуле объединена в одну [большую задачу по предсказанию данных](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview). В ходе выполнения модуля мы будем разбирать определенные техники, которые нужны для ее решения. Настоятельно рекомендуем выполнить все шаги **по порядку**, тогда в конце вы получите решение большой реальной задачи по МЛ.\n",
    "\n",
    "Нам даны [данные](https://yadi.sk/d/tcElz6cqSNpPqA) о домах выставленных на продажу. Нам необходимо решить задачу регрессии и предсказать цену продажи дома для $X_{test}$ по данным $X_{train}$ и $y_{train}$. В нашем случае  $y_{train}$ - это столбик `SalePrice`, $X_{train}$ - все остальные столбики.\n",
    "\n",
    "На вход подается 2 считанных датафрейма **df_train**, **df_test** из файлов без изменений. \n",
    "\n",
    "Начальная подготовка:\n",
    "\n",
    "* Разделить **df_train** на **X_train**(`pd.Dataframe`) и **y_train**(`pd.Series`).\n",
    "* Сконкатенировать **X_train** и **df_test** в **df** по вертикали (можно ориентироваться по столбику `Id` они как раз идут по-порядку). Не забудьте обновить индекс!\n",
    "\n",
    "Задачи:\n",
    "\n",
    "* Заменить в **df** все Nan-ы в категориальных признаках (`object`) на строку `missing`\n",
    "* Заменить в **df** все Nan-ы в числовых признаках на 0.\n",
    "\n",
    "Вернуть из функции измененный **df**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def split_X_y(df):\n",
    "    X, y = df.iloc[:, 0:-1], df.iloc[:, -1:]\n",
    "    return X, y\n",
    "\n",
    "def del_nan(df_train: pd.DataFrame, X_test: pd.DataFrame) -> pd.DataFrame:\n",
    "    X, y = split_X_y(df_train)\n",
    "    \n",
    "    df = pd.concat([X, X_test])\n",
    "    df = df.reset_index()\n",
    "    print(X.shape, y.shape, X_test.shape, df.shape)\n",
    "    cat = df.select_dtypes(include=['object']).columns\n",
    "    num = df.select_dtypes(exclude=['object']).columns\n",
    "    df[cat] = df[cat].fillna('missing')\n",
    "    df[num] = df[num].fillna(0)\n",
    "\n",
    "    print(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street    Alley  \\\n",
      "0        1          60       RL         65.0     8450   Pave  missing   \n",
      "1        2          20       RL         80.0     9600   Pave  missing   \n",
      "2        3          60       RL         68.0    11250   Pave  missing   \n",
      "3        4          70       RL         60.0     9550   Pave  missing   \n",
      "4        5          60       RL         84.0    14260   Pave  missing   \n",
      "...    ...         ...      ...          ...      ...    ...      ...   \n",
      "2914  2915         160       RM         21.0     1936   Pave  missing   \n",
      "2915  2916         160       RM         21.0     1894   Pave  missing   \n",
      "2916  2917          20       RL        160.0    20000   Pave  missing   \n",
      "2917  2918          85       RL         62.0    10441   Pave  missing   \n",
      "2918  2919          60       RL         74.0     9627   Pave  missing   \n",
      "\n",
      "     LotShape LandContour Utilities  ... ScreenPorch PoolArea   PoolQC  \\\n",
      "0         Reg         Lvl    AllPub  ...           0        0  missing   \n",
      "1         Reg         Lvl    AllPub  ...           0        0  missing   \n",
      "2         IR1         Lvl    AllPub  ...           0        0  missing   \n",
      "3         IR1         Lvl    AllPub  ...           0        0  missing   \n",
      "4         IR1         Lvl    AllPub  ...           0        0  missing   \n",
      "...       ...         ...       ...  ...         ...      ...      ...   \n",
      "2914      Reg         Lvl    AllPub  ...           0        0  missing   \n",
      "2915      Reg         Lvl    AllPub  ...           0        0  missing   \n",
      "2916      Reg         Lvl    AllPub  ...           0        0  missing   \n",
      "2917      Reg         Lvl    AllPub  ...           0        0  missing   \n",
      "2918      Reg         Lvl    AllPub  ...           0        0  missing   \n",
      "\n",
      "        Fence MiscFeature MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
      "0     missing     missing       0      2    2008        WD         Normal  \n",
      "1     missing     missing       0      5    2007        WD         Normal  \n",
      "2     missing     missing       0      9    2008        WD         Normal  \n",
      "3     missing     missing       0      2    2006        WD        Abnorml  \n",
      "4     missing     missing       0     12    2008        WD         Normal  \n",
      "...       ...         ...     ...    ...     ...       ...            ...  \n",
      "2914  missing     missing       0      6    2006        WD         Normal  \n",
      "2915  missing     missing       0      4    2006        WD        Abnorml  \n",
      "2916  missing     missing       0      9    2006        WD        Abnorml  \n",
      "2917    MnPrv        Shed     700      7    2006        WD         Normal  \n",
      "2918  missing     missing       0     11    2006        WD         Normal  \n",
      "\n",
      "[2919 rows x 80 columns]\n",
      "(1460, 80) (1460, 1) (1459, 80) (2919, 81)\n",
      "      index    Id  MSSubClass MSZoning  LotFrontage  LotArea Street    Alley  \\\n",
      "0         0     1          60       RL         65.0     8450   Pave  missing   \n",
      "1         1     2          20       RL         80.0     9600   Pave  missing   \n",
      "2         2     3          60       RL         68.0    11250   Pave  missing   \n",
      "3         3     4          70       RL         60.0     9550   Pave  missing   \n",
      "4         4     5          60       RL         84.0    14260   Pave  missing   \n",
      "...     ...   ...         ...      ...          ...      ...    ...      ...   \n",
      "2914   1454  2915         160       RM         21.0     1936   Pave  missing   \n",
      "2915   1455  2916         160       RM         21.0     1894   Pave  missing   \n",
      "2916   1456  2917          20       RL        160.0    20000   Pave  missing   \n",
      "2917   1457  2918          85       RL         62.0    10441   Pave  missing   \n",
      "2918   1458  2919          60       RL         74.0     9627   Pave  missing   \n",
      "\n",
      "     LotShape LandContour  ... ScreenPorch PoolArea   PoolQC    Fence  \\\n",
      "0         Reg         Lvl  ...           0        0  missing  missing   \n",
      "1         Reg         Lvl  ...           0        0  missing  missing   \n",
      "2         IR1         Lvl  ...           0        0  missing  missing   \n",
      "3         IR1         Lvl  ...           0        0  missing  missing   \n",
      "4         IR1         Lvl  ...           0        0  missing  missing   \n",
      "...       ...         ...  ...         ...      ...      ...      ...   \n",
      "2914      Reg         Lvl  ...           0        0  missing  missing   \n",
      "2915      Reg         Lvl  ...           0        0  missing  missing   \n",
      "2916      Reg         Lvl  ...           0        0  missing  missing   \n",
      "2917      Reg         Lvl  ...           0        0  missing    MnPrv   \n",
      "2918      Reg         Lvl  ...           0        0  missing  missing   \n",
      "\n",
      "     MiscFeature MiscVal MoSold YrSold  SaleType  SaleCondition  \n",
      "0        missing       0      2   2008        WD         Normal  \n",
      "1        missing       0      5   2007        WD         Normal  \n",
      "2        missing       0      9   2008        WD         Normal  \n",
      "3        missing       0      2   2006        WD        Abnorml  \n",
      "4        missing       0     12   2008        WD         Normal  \n",
      "...          ...     ...    ...    ...       ...            ...  \n",
      "2914     missing       0      6   2006        WD         Normal  \n",
      "2915     missing       0      4   2006        WD        Abnorml  \n",
      "2916     missing       0      9   2006        WD        Abnorml  \n",
      "2917        Shed     700      7   2006        WD         Normal  \n",
      "2918     missing       0     11   2006        WD         Normal  \n",
      "\n",
      "[2919 rows x 81 columns]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "DataFrame are different\n\nDataFrame shape mismatch\n[left]:  (2919, 81)\n[right]: (2919, 80)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-193-049f5c64f216>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdel_nan_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m######################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0massert_frame_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdel_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdel_nan_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m######################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: DataFrame are different\n\nDataFrame shape mismatch\n[left]:  (2919, 81)\n[right]: (2919, 80)"
     ]
    }
   ],
   "source": [
    "del_nan_df = pd.read_csv('data/del_nan.csv')\n",
    "print(del_nan_df)\n",
    "######################################################\n",
    "assert_frame_equal(del_nan(train, test), del_nan_df)\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "...          ...       ...  ...      ...    ...    ...         ...     ...   \n",
       "1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
       "1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n",
       "1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0         2   2008        WD         Normal     208500  \n",
       "1         5   2007        WD         Normal     181500  \n",
       "2         9   2008        WD         Normal     223500  \n",
       "3         2   2006        WD        Abnorml     140000  \n",
       "4        12   2008        WD         Normal     250000  \n",
       "...     ...    ...       ...            ...        ...  \n",
       "1455      8   2007        WD         Normal     175000  \n",
       "1456      2   2010        WD         Normal     210000  \n",
       "1457      5   2010        WD         Normal     266500  \n",
       "1458      4   2010        WD         Normal     142125  \n",
       "1459      6   2008        WD         Normal     147500  \n",
       "\n",
       "[1460 rows x 81 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1936</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1894</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>160.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>85</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>10441</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>700</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9627</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0     1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
       "1     1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
       "2     1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
       "3     1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
       "4     1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1454  2915         160       RM         21.0     1936   Pave   NaN      Reg   \n",
       "1455  2916         160       RM         21.0     1894   Pave   NaN      Reg   \n",
       "1456  2917          20       RL        160.0    20000   Pave   NaN      Reg   \n",
       "1457  2918          85       RL         62.0    10441   Pave   NaN      Reg   \n",
       "1458  2919          60       RL         74.0     9627   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence  \\\n",
       "0            Lvl    AllPub  ...         120        0    NaN  MnPrv   \n",
       "1            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "2            Lvl    AllPub  ...           0        0    NaN  MnPrv   \n",
       "3            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "4            HLS    AllPub  ...         144        0    NaN    NaN   \n",
       "...          ...       ...  ...         ...      ...    ...    ...   \n",
       "1454         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "1455         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "1456         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "1457         Lvl    AllPub  ...           0        0    NaN  MnPrv   \n",
       "1458         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "\n",
       "     MiscFeature MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0            NaN       0      6    2010        WD         Normal  \n",
       "1           Gar2   12500      6    2010        WD         Normal  \n",
       "2            NaN       0      3    2010        WD         Normal  \n",
       "3            NaN       0      6    2010        WD         Normal  \n",
       "4            NaN       0      1    2010        WD         Normal  \n",
       "...          ...     ...    ...     ...       ...            ...  \n",
       "1454         NaN       0      6    2006        WD         Normal  \n",
       "1455         NaN       0      4    2006        WD        Abnorml  \n",
       "1456         NaN       0      9    2006        WD        Abnorml  \n",
       "1457        Shed     700      7    2006        WD         Normal  \n",
       "1458         NaN       0     11    2006        WD         Normal  \n",
       "\n",
       "[1459 rows x 80 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
      "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
      "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
      "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
      "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
      "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
      "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
      "\n",
      "     LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence  \\\n",
      "0            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
      "1            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
      "2            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
      "3            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
      "4            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
      "...          ...       ...  ...         ...      ...    ...    ...   \n",
      "1455         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
      "1456         Lvl    AllPub  ...           0        0    NaN  MnPrv   \n",
      "1457         Lvl    AllPub  ...           0        0    NaN  GdPrv   \n",
      "1458         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
      "1459         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
      "\n",
      "     MiscFeature MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
      "0            NaN       0      2    2008        WD         Normal  \n",
      "1            NaN       0      5    2007        WD         Normal  \n",
      "2            NaN       0      9    2008        WD         Normal  \n",
      "3            NaN       0      2    2006        WD        Abnorml  \n",
      "4            NaN       0     12    2008        WD         Normal  \n",
      "...          ...     ...    ...     ...       ...            ...  \n",
      "1455         NaN       0      8    2007        WD         Normal  \n",
      "1456         NaN       0      2    2010        WD         Normal  \n",
      "1457        Shed    2500      5    2010        WD         Normal  \n",
      "1458         NaN       0      4    2010        WD         Normal  \n",
      "1459         NaN       0      6    2008        WD         Normal  \n",
      "\n",
      "[1460 rows x 80 columns] Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n",
      "\n",
      "[1460 rows x 0 columns]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "DataFrame Expected type <class 'pandas.core.frame.DataFrame'>, found <class 'NoneType'> instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-6ace3d5b8190>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdel_nan_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/del_nan.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m######################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0massert_frame_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdel_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdel_nan_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m######################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/_testing.py\u001b[0m in \u001b[0;36m_check_isinstance\u001b[0;34m(left, right, cls)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         raise AssertionError(\n\u001b[0m\u001b[1;32m    386\u001b[0m             \u001b[0;34mf\"{cls_name} Expected type {cls}, found {type(left)} instead\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         )\n",
      "\u001b[0;31mAssertionError\u001b[0m: DataFrame Expected type <class 'pandas.core.frame.DataFrame'>, found <class 'NoneType'> instead"
     ]
    }
   ],
   "source": [
    "del_nan_df = pd.read_csv('data/del_nan.csv')\n",
    "######################################################\n",
    "assert_frame_equal(del_nan(train, test), del_nan_df)\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Порядковые категории"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам на вход приходит **df** из предыдущей задачи.\n",
    "\n",
    "Если внимательно изучить файл `data_description` можно понять, что многие категориальные признаки - порядковые (упорядоченное множество). Значит их можно перевести в осмысленные числа. Значит тут можно воспользоваться `LabelEncoding`.\n",
    "\n",
    "Ваша задача: заменить в **df** категориальные признаки на числовые, для порядковых признаков.\n",
    "\n",
    "На выходе возвращаем измененный **df**.\n",
    "\n",
    "Чтобы слегка упростить вам жизнь, вот вам готовые словари для перевода. Однако к каким столбцам их применять - вы должны выяснить сами, изучив файл `data_description`. Каждый маппинг используется хотя бы 1 раз, а некоторые и не по одному разу.\n",
    "\n",
    "```python\n",
    "{'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'missing':0}\n",
    "{'Gd':4, 'Av': 3, 'Mn': 2, 'No': 1, 'missing': 0}\n",
    "{'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, 'missing': 0}\n",
    "{'Typ': 8, 'Min1': 7, 'Min2': 6, 'Mod': 5, 'Maj1': 4, 'Maj2': 3, 'Sev': 2, 'Sal': 1, 'missing': 0}\n",
    "{'Fin': 3, 'RFn': 2, 'Unf': 1, 'missing': 0}\n",
    "{'GdPrv': 4, 'MnPrv': 3, 'GdWo': 2, 'MnWw': 1, 'missing': 0}\n",
    "{'Reg': 4, 'IR1': 3, 'IR2': 2, 'IR3': 1, 'missing': 0}\n",
    "{'Lvl': 4, 'Bnk': 3, 'HLS':2,'Low':1, 'missing': 0}\n",
    "{'AllPub':4, 'NoSewr':3, 'NoSeWa':2, 'ELO':1, 'missing':0}\n",
    "{'Gtl':3, 'Mod':2, 'Sev':1, 'missing':0}\n",
    "{'SBrkr':5, 'FuseA':4, 'FuseF':3, 'FuseP':2, 'Mix':1, 'missing':0}\n",
    "{'Y':3, 'P':2, 'N':1, 'missing':0}\n",
    "{'Y':1, 'N':0, 'missing':0} #тут нет ошибки, все так и задумано:)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hint\n",
    "После перевода у вас должно **остаться** 20 категориальных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def cat_to_num(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_nan_df = pd.read_csv('data/del_nan.csv')\n",
    "answer = pd.read_csv('data/cat_to_num.csv')\n",
    "######################################################\n",
    "cat_to_num_df = cat_to_num(del_nan_df)\n",
    "assert_frame_equal(cat_to_num_df, answer)\n",
    "\n",
    "categorical_cols = [col for col in cat_to_num_df.columns if cat_to_num_df[col].dtypes == \"object\"]\n",
    "assert len(categorical_cols) == 20\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. One hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь разберемся с непорядковыми категориальными признаками.\n",
    "\n",
    "Для начала заметим признак `MSSubClass`, у которого тип `int64`, но если посмотреть в описание `data_description` можно понять, что это - категориальный признак. \n",
    "\n",
    "* Измените тип признака `MSSubClass` с `int64` на `object`\n",
    "\n",
    "Теперь можно сделать `One hot encoding`:\n",
    "\n",
    "* Найдите все колонки с категориальными признаками и составьте из них отдельный **df_oh** `pd.DataFrame` (индекс сохранить прежний)\n",
    "* Применить к полученному фрейму **df_oh** функцию [`pd.get_dummies`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) (Реализует `One Hot Encoding`)\n",
    "* Удалить категориальные колонки из **df** и добавить справа к **df** фрейм с `One Hot Encoding`\n",
    " \n",
    "Вернуть из функции **df**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hint\n",
    "Итого должно получится 238 колонка из них 179 пришли из `One hot encoding` фрейма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def one_hot(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_to_num_df = pd.read_csv('data/cat_to_num.csv')\n",
    "one_hot_ans = pd.read_csv('data/one_hot.csv')\n",
    "######################################################\n",
    "one_hot_df = one_hot(cat_to_num_df)\n",
    "assert_frame_equal(one_hot_df.astype('float64').reindex(sorted(one_hot_df.columns), axis=1), \n",
    "                   one_hot_ans.astype('float64').reindex(sorted(one_hot_ans.columns), axis=1))\n",
    "\n",
    "assert one_hot_df.shape[1] == 238\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Некоррелирующие признаки "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы разобрались с категориальными признаками, теперь разберемся с числовыми.\n",
    "Для числовых признаков можно посчитать корреляцию с правильным ответом. Если признаки слабо коррелируют, то они нам не нужны. Например колонка `Id` явно никак не влияет на стоимость дома.\n",
    "\n",
    "Вам на вход передается изначальный **df_train** и **df** полученный из предыдущей задачи.\n",
    "\n",
    "Ваша задача: \n",
    "\n",
    "* найти корреляцию всех **числовых** признаков **df_train** с признаком `SalePrice` с помощью `pd.corr`\n",
    "* если абсолютное значение корреляции признака с `SalePrice` меньше $0.05$ - удалите этот признак из **df**\n",
    "\n",
    "Верните измененный **df** и столбец корреляции признаков с признаком `SalePrice` упорядоченный по убыванию. Начало столбца корреляции выглядит следующим образом:\n",
    "\n",
    "|               |SalePrice |\n",
    "|---------------|----------|\n",
    "|**SalePrice**  |1.000000  |\n",
    "|**OverallQual**|0.790982  |\n",
    "|**GrLivArea**  |0.708624  |\n",
    "|**GarageCars** |0.640409  |\n",
    "|**GarageArea** |0.623431  |\n",
    "|**TotalBsmtSF**|0.613581  |\n",
    "|**1stFlrSF**   |0.605852  |\n",
    "|**FullBath**   |0.560664  |\n",
    "\n",
    "Всего должно получиться 37 числовых признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(df: pd.DataFrame, df_train: pd.DataFrame) -> (pd.DataFrame, pd.DataFrame):\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_df = pd.read_csv('data/one_hot.csv')\n",
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "ans_corr_df = pd.read_csv('data/corr_df.csv')\n",
    "ans_corr = pd.read_csv('data/corr.csv').set_index('Unnamed: 0')\n",
    "######################################################\n",
    "corr_df, corr = correlation(one_hot_df, df_train)\n",
    "\n",
    "assert_frame_equal(corr_df.astype('float64').reindex(sorted(corr_df.columns), axis=1),\n",
    "                   ans_corr_df.astype('float64').reindex(sorted(ans_corr_df.columns), axis=1))\n",
    "\n",
    "assert_array_almost_equal(corr.values, ans_corr.values, decimal=4)\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Feature Engineering и Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу 2 простые задачки:\n",
    "\n",
    "1) Давайте нагенерируем несколько фич во входном фрейме **df**:\n",
    "\n",
    "    * `TotalArea` = `TotalBsmtSF` + `1stFlrSF` + `2ndFlrSF` + `GrLivArea` + `GarageArea`\n",
    "    * `YearAverage` = (`YearRemodAdd` + `YearBuilt`) / 2\n",
    "    * `LiveAreaQual` = `OverallQual` * `GrLivArea`\n",
    "\n",
    "    На выход отправьте **df** c тремя новымим столбиками. столбцы должны идти в том же порядки что указаны в списке в хвосте **df**.\n",
    "\n",
    "2) У стандартного и нормального масштабирования есть одна проблема: она учитывает все признаки, даже те, которые изначально некорректны (шум, выбросы). Чтобы избавитьться от шумов и выбросов и корректно масштабировать выборку необходимо использовать [RobustScaling](https://scikit-learn.org/0.18/auto_examples/preprocessing/plot_robust_scaling.html).\n",
    "\n",
    "    Ваша задача - отмасштабировать полученный фрейм с помощью `RobustScaler`. И вернуть отмасштабированный массив (да, скалирование возвращает массив, а не DataFrame)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def feature_en(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass\n",
    "\n",
    "def scaling(df: pd.DataFrame) -> np.array:\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = pd.read_csv('data/corr_df.csv')\n",
    "ans_feature_df = pd.read_csv('data/feature_df.csv')\n",
    "######################################################\n",
    "\n",
    "feature_df = feature_en(corr_df)\n",
    "\n",
    "assert_frame_equal(feature_df.astype('float64').reindex(sorted(feature_df.columns), axis=1),\n",
    "                   ans_feature_df.astype('float64').reindex(sorted(ans_feature_df.columns), axis=1))\n",
    "######################################################\n",
    "feature_df = pd.read_csv('data/feature_df.csv')\n",
    "ans_scale_df = pd.read_csv('data/scale_df.csv').values\n",
    "######################################################\n",
    "\n",
    "scale_df = scaling(feature_df)\n",
    "\n",
    "assert_array_almost_equal(scale_df,\n",
    "                          ans_scale_df,\n",
    "                          decimal=6)\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Смешанная модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, теперь мы готовы обучать модель! Осталось изучить последний интересный трюк - смешанные модели.\n",
    "\n",
    "Возьмем [2 регрессии](https://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b):\n",
    "\n",
    "* Ridge\n",
    "* Lasso\n",
    " \n",
    "Найдем оптимальные значения $\\alpha$ для обеих регрессий с помощью GridSearch.\n",
    "\n",
    "Теперь отправим обе модели с наилучшими параметрами в класс указанный снизу. Это класс смешения моделей. В нем параметр $\\beta \\in [0,1]$ - это коэффициент, с которым берется ответ одного классификаторв, а ответ второго - с коэффициентом $(1 - \\beta)$. Такая техника нередко позволяет добиться лучших результатов, чем одна модель.\n",
    "\n",
    "Теперь найдем наилучшее $\\beta$ для смешенной модели также с помощью GridSearch. Осталось получить **y_pred** с помощью наилучшей смешанной модели.\n",
    "\n",
    "На вход вы получаете **X_scaled** из предыдущей задачи и **df_train** начальный. Мы подготовили за вас **X_train**, **y_train** и **X_test**. \n",
    "\n",
    "В задаче необходимо минимизировать метрику `neg_mean_squared_log_error`. Для удобства мы возьмем `np.log1p(y_train)` и будем минимизировать метрику `neg_mean_squared_error`. Эту метрику необходимо минимизировать у всех 3-х GridSearch.\n",
    "\n",
    "На выход отправьте GridSearch объект смешанной модели, а также результат **y_test**. (Не забудьте его проэкспоненциировать).\n",
    "\n",
    "Мы выдаем вам ориентировачные параметры для каждого GridSearch. Вы можете увеличить перебор, чтобы получить лучшую модель.\n",
    "```python\n",
    "params_ridge = {'alpha': np.arange(1, 20)}\n",
    "params_lasso = {'alpha': np.logspace(-4, 3, num=8, base=10)}\n",
    "params_blend = {'beta': np.linspace(0, 1, 11)}\n",
    "```\n",
    "\n",
    "Первые 2 GridSearch **не нужно** писать в функции: они могут работать достаточно долго и превысят лимит работы задачи на сервере. Найдите у себя локально наилучшие параметры и уже с этими параметрами создайте смешанную модель внутри функции. \n",
    "\n",
    "Также не нужно сильно увеличивать перебор для $\\beta$ - того, что есть, более чем достаточно.\n",
    "\n",
    "P.S. Осталось сохранить файл с **y_test** и отправить его в [соревнование](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/submit). \n",
    "\n",
    "Улучшайте свои результы пробуя другие модели и другие параметры. Уберите больше ненужных признаков, добавьте новые фичи. Экспериментируйте и дерзайте!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "class BlendRegressor(BaseEstimator): # предок класса классификаторов, чтобы можно было засунуть в GridSearch\n",
    "    def __init__(self, clf1, clf2, beta=0.5):\n",
    "        self.clf1 = clf1 \n",
    "        self.clf2 = clf2\n",
    "        self.beta = beta #параметр смешивания\n",
    "\n",
    "    def fit(self, X, y): #обучаем классификатор\n",
    "        self.X_ = X\n",
    "        self.y_ = y \n",
    "        self.clf1.fit(X, y)\n",
    "        self.clf2.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X): #возвращаем значения \n",
    "        return self.clf1.predict(X) * self.beta + self.clf2.predict(X) * (1 - self.beta)\n",
    "\n",
    "    \n",
    "def learning(X_scaled: np.array, df_train: pd.DataFrame) -> (GridSearchCV, np.array):\n",
    "    X_train = X_scaled[0: len(df_train),]\n",
    "    X_test  = X_scaled[len(df_train): len(X_scaled)]\n",
    "    y_train = np.log1p(df_train['SalePrice'])\n",
    "    \n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    \n",
    "    return blend_gs, np.exp(y_test) - 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
