{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from numpy.testing import assert_array_equal, assert_array_almost_equal, assert_equal, assert_almost_equal\n",
    "from pandas.testing import assert_frame_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Основы метрик классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На вход подаются 2 массива: \n",
    "\n",
    "* $y_{real}$ - реальные значения бинарных классов\n",
    "* $y_{pred}$ - предсказанные значения бинарных классов. \n",
    "\n",
    "Вам необходимо посчитать, **не используя** стандартные функции, метрики: \n",
    "\n",
    "* $accuracy$\n",
    "* $precision$\n",
    "* $recall$\n",
    "* $F_1$\n",
    "\n",
    "Возвращать числа нужно именно в данном порядке.\n",
    "\n",
    "### Sample 1\n",
    "#### Input:\n",
    "```python\n",
    "y_real = np.array([0, 1, 0, 0, 1, 1, 1, 1])\n",
    "y_pred = np.array([0, 1, 1, 0, 1, 1, 0, 0])\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "0.625, 0.75, 0.6, 0.66\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def main_metrics(y_real: np.array, y_pred: np.array) -> (float, float, float, float):\n",
    "    acc = np.mean(y_real==y_pred)\n",
    "    tp = (y_real*y_pred).sum() # true positive\n",
    "    fn = (y_real * (y_pred ^ y_real)).sum() # false negative\n",
    "    fp = (y_pred * (y_pred ^ y_real)).sum()\n",
    "    tn = ((1 - y_real) * (1 - y_pred)).sum()\n",
    "    \n",
    "    \n",
    "    pre = tp / (fp + tp)\n",
    "    rec = tp / (fn + tp)\n",
    "    f1 = 2 * pre * rec / (pre + rec)\n",
    "    return (acc, pre, rec, f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOLUTION ALTERNATIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def perf_measure(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "           TP += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "           TN += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)\n",
    "\n",
    "\n",
    "def main_metrics(y_real: np.array, y_pred: np.array) -> (float, float, float, float):\n",
    "    acc = np.mean(y_real==y_pred)\n",
    "    TP, FP, TN, FN = perf_measure(y_real, y_pred)\n",
    "    pre = TP / (FP + TP)\n",
    "    rec = TP / (FN + TP)\n",
    "    f1 = 2 * pre * rec / (pre + rec)\n",
    "    return (acc, pre, rec, f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "######################################################\n",
    "y_real = np.array([0, 1, 0, 0, 1, 1, 1, 1])\n",
    "y_pred = np.array([0, 1, 1, 0, 1, 1, 0, 0])\n",
    "\n",
    "\n",
    "acc, pre, rec, f1 = main_metrics(y_real, y_pred)\n",
    "\n",
    "assert np.abs(acc - accuracy_score(y_real, y_pred)) < 0.001\n",
    "assert np.abs(pre - precision_score(y_real, y_pred)) < 0.001, (pre, precision_score(y_real, y_pred), pre- precision_score(y_real, y_pred) )\n",
    "assert np.abs(rec - recall_score(y_real, y_pred)) < 0.001\n",
    "assert np.abs(f1  - f1_score(y_real, y_pred)) < 0.001\n",
    "######################################################\n",
    "y_real = np.random.choice(2, 1000)\n",
    "y_pred = np.random.choice(2, 1000)\n",
    "\n",
    "acc, pre, rec, f1 = main_metrics(y_real, y_pred)\n",
    "\n",
    "assert np.abs(acc - accuracy_score(y_real, y_pred)) < 0.001\n",
    "assert np.abs(pre - precision_score(y_real, y_pred)) < 0.001\n",
    "assert np.abs(rec - recall_score(y_real, y_pred)) < 0.001\n",
    "assert np.abs(f1  - f1_score(y_real, y_pred)) < 0.001\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Основы метрик регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решаем задачу регрессии. На вход подаются 2 массива: $y_{real}$ - реальные значения функции и $y_{pred}$ - предсказанные значения функции. \n",
    "\n",
    "Вам необходимо посчитать, **не используя** стандартные функции, метрики: \n",
    "\n",
    "* $R^2score$\n",
    "* $MAE$ - `mean_absolute_error`\n",
    "* $MSE$ - `mean_squared_error`\n",
    "* $MSLE$ - `mean_squared_log_error`\n",
    "\n",
    "Возвращать числа нужно именно в данном порядке.\n",
    "\n",
    "Можете сверяться с реальными метриками в `sklearn.metrics`.\n",
    "\n",
    "Все числа в тестах больше 0, поэтому $MSLE$ будет считаться корректно.\n",
    "### Sample 1\n",
    "#### Input:\n",
    "```python\n",
    "y_real = np.array([1, 2, 3, 4, 6])\n",
    "y_pred = np.array([1, 3, 2, 4, 5])\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "0.797297, 0.6, 0.6, 0.037856\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def reg_metrics(x: np.array, y: np.array) -> (float, float, float, float):\n",
    "    r2 = 1 - ((x - y) ** 2).sum() / ((x - np.mean(x)) ** 2).sum()\n",
    "    mae = np.mean(np.abs(x - y))\n",
    "    mse = ((x - y) * (x - y)).sum() / len(x)\n",
    "    a = np.log(x + 1) - np.log(y + 1)\n",
    "    msle = (a * a).sum() / len(x)\n",
    "    return r2, mae, mse, msle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score as R2, mean_absolute_error as MAE, mean_squared_log_error as MSLE, mean_squared_error as MSE \n",
    "######################################################\n",
    "y_real = np.array([1,2,3,4,6])\n",
    "y_pred = np.array([1,3,2,4,5])\n",
    "\n",
    "\n",
    "r2, mae, mse, msle = reg_metrics(y_real, y_pred)\n",
    "\n",
    "assert np.abs(r2 - R2(y_real, y_pred)) < 0.001\n",
    "assert np.abs(mae - MAE(y_real, y_pred)) < 0.001\n",
    "assert np.abs(mse - MSE(y_real, y_pred)) < 0.001\n",
    "assert np.abs(msle  - MSLE(y_real, y_pred)) < 0.001\n",
    "######################################################\n",
    "y_real = np.random.choice(1000, 1000)\n",
    "y_pred = np.random.choice(1000, 1000)\n",
    "\n",
    "r2, mae, mse, msle = reg_metrics(y_real, y_pred)\n",
    "\n",
    "assert np.abs(r2 - R2(y_real, y_pred)) < 0.001\n",
    "assert np.abs(mae - MAE(y_real, y_pred)) < 0.001\n",
    "assert np.abs(mse - MSE(y_real, y_pred)) < 0.001\n",
    "assert np.abs(msle  - MSLE(y_real, y_pred)) < 0.001\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Нахождение Roc-curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам на вход даны $y_{real}$ и массив вероятностей $y_{prob} = P(y_{pred}=1)$ необходимо реализовать функцию `roc-curve`, которая вернет 2 массива различных значений $fpr$ и $tpr$, для дальнейшего построения $Roc$ кривой.\n",
    "\n",
    "Можно считать, что все вероятности ограничены $decimal=2$ (у каждого числа не более 2-х знаков после запятой).\n",
    "\n",
    "### Sample\n",
    "#### Input:\n",
    "```python\n",
    "y_real = np.array([  1,   1,   0,   0,   0,   1,   0,   1,   0])\n",
    "y_prob = np.array([0.8, 0.8, 0.2, 0.2, 0.6, 0.4, 0.6, 0.6, 0.4])\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "array([0.,  0.,  0.4, 0.6, 1. ]), #fpr\n",
    "array([0., 0.5, 0.75,  1., 1. ])  #tpr\n",
    "```\n",
    "\n",
    "### Sample 2\n",
    "#### Input:\n",
    "```python\n",
    "y_real = np.array([  1,   1,   0,   0,   1,   0,   1,   0])\n",
    "y_prob = np.array([0.8, 0.8, 0.2, 0.2, 0.4, 0.4, 0.6, 0.6])\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "array([0.,  0., 0.25, 0.5, 1. ]), #fpr\n",
    "array([0., 0.5, 0.75,  1., 1. ])  #tpr\n",
    "\n",
    "или \n",
    "\n",
    "array([0.,  0., 0.5, 1. ]), #fpr\n",
    "array([0., 0.5,  1., 1. ])  #tpr\n",
    "```\n",
    "\n",
    "Обратите внимание на 2 пример: roc кривая, которая задается ими - одинаковая. Точка, которая уходит, находится на прямой между двумя соседними, в целом такие точки можно убирать, но будут приниматься оба варианта. Функция `sklearn.metrics.roc_curve` возвращает второй вариант."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "def roc(y_real: np.array, y_prob: np.array) -> (np.array, np.array):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_real, y_prob, pos_label=None)\n",
    "    print(fpr, tpr, sep='\\n')\n",
    "    return     fpr, tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.  0.4 0.6 1. ]\n",
      "[0.   0.5  0.75 1.   1.  ]\n",
      "[0.  0.  0.5 1. ]\n",
      "[0.  0.5 1.  1. ]\n",
      "[0.         0.00796813 0.02390438 0.03386454 0.03984064 0.04581673\n",
      " 0.05179283 0.05976096 0.07171315 0.07968127 0.09561753 0.10358566\n",
      " 0.11155378 0.11952191 0.12749004 0.13346614 0.14940239 0.15737052\n",
      " 0.17131474 0.187251   0.20119522 0.21115538 0.22310757 0.23705179\n",
      " 0.24900398 0.25697211 0.26294821 0.27290837 0.27689243 0.29282869\n",
      " 0.29880478 0.31474104 0.31673307 0.32270916 0.32868526 0.33864542\n",
      " 0.35059761 0.36055777 0.37051793 0.38247012 0.39043825 0.40039841\n",
      " 0.41035857 0.42231076 0.42828685 0.43625498 0.4501992  0.4561753\n",
      " 0.46613546 0.48007968 0.49203187 0.5059761  0.51792829 0.52390438\n",
      " 0.53386454 0.55179283 0.56175299 0.57171315 0.58565737 0.59561753\n",
      " 0.60756972 0.61752988 0.62749004 0.63545817 0.64741036 0.65338645\n",
      " 0.66135458 0.67131474 0.67928287 0.69322709 0.69721116 0.70916335\n",
      " 0.71912351 0.72709163 0.73705179 0.74103586 0.75099602 0.75896414\n",
      " 0.7689243  0.77290837 0.79083665 0.81075697 0.82270916 0.83665339\n",
      " 0.85059761 0.85657371 0.86653386 0.87848606 0.88446215 0.89641434\n",
      " 0.90039841 0.91035857 0.91434263 0.93227092 0.94023904 0.95219124\n",
      " 0.96215139 0.96812749 0.97609562 0.99203187 1.        ]\n",
      "[0.         0.00401606 0.02208835 0.03012048 0.04016064 0.04618474\n",
      " 0.0562249  0.06827309 0.07630522 0.08232932 0.08835341 0.10040161\n",
      " 0.1064257  0.11445783 0.12048193 0.13253012 0.15261044 0.16064257\n",
      " 0.1746988  0.18674699 0.19678715 0.21084337 0.2188755  0.22891566\n",
      " 0.25502008 0.25903614 0.26104418 0.27108434 0.2751004  0.28514056\n",
      " 0.29718876 0.31526104 0.3253012  0.33333333 0.33935743 0.35341365\n",
      " 0.36345382 0.37349398 0.38955823 0.39558233 0.40160643 0.40963855\n",
      " 0.41967871 0.42771084 0.44176707 0.44779116 0.45783133 0.46987952\n",
      " 0.47590361 0.47991968 0.4939759  0.50200803 0.51405622 0.52008032\n",
      " 0.53212851 0.54216867 0.55421687 0.562249   0.57228916 0.57831325\n",
      " 0.58433735 0.59036145 0.59839357 0.60441767 0.61646586 0.62650602\n",
      " 0.63855422 0.65060241 0.6746988  0.68875502 0.69678715 0.70481928\n",
      " 0.70883534 0.72690763 0.74497992 0.75301205 0.76104418 0.76907631\n",
      " 0.7811245  0.79718876 0.80522088 0.80923695 0.81726908 0.82128514\n",
      " 0.83333333 0.84538153 0.85140562 0.86144578 0.86546185 0.87349398\n",
      " 0.88353414 0.89558233 0.90763052 0.92168675 0.93574297 0.9497992\n",
      " 0.96184739 0.96987952 0.97590361 0.98995984 1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import auc, roc_curve\n",
    "######################################################\n",
    "y_real = np.array([  1,   1,   0,   0,   0,   1,   0,   1,   0])\n",
    "y_prob = np.array([0.8, 0.8, 0.2, 0.2, 0.6, 0.4, 0.6, 0.6, 0.4])\n",
    "fpr_true, tpr_true, _ = roc_curve(y_real, y_prob)\n",
    "fpr, tpr = roc(y_real, y_prob)\n",
    "\n",
    "assert auc(fpr, tpr) - auc(fpr_true, tpr_true) < 0.01\n",
    "######################################################\n",
    "y_real = np.array([  1,   1,   0,   0,   1,   0,   1,   0])\n",
    "y_prob = np.array([0.8, 0.8, 0.2, 0.2, 0.4, 0.4, 0.6, 0.6])\n",
    "fpr_true, tpr_true, _  = roc_curve(y_real, y_prob)\n",
    "fpr, tpr = roc(y_real, y_prob)\n",
    "\n",
    "assert auc(fpr, tpr) - auc(fpr_true, tpr_true) < 0.01\n",
    "######################################################\n",
    "y_real = np.random.choice(2, 1000) \n",
    "y_prob = np.random.choice(101, 1000) / 100\n",
    "\n",
    "fpr_true, tpr_true, _  = roc_curve(y_real, y_prob)\n",
    "fpr, tpr = roc(y_real, y_prob)\n",
    "\n",
    "assert auc(fpr, tpr) - auc(fpr_true, tpr_true) < 0.01\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C помощью [GridSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) найдите лучшие коэффициенты гиперпараметров `max_depth` и `min_samples_leaf` для классификатора [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) и верните обученный grid_search. \n",
    "\n",
    "* Пределы `max_depth` $(1, 10)$ \n",
    "* Пределы `min_samples_leaf` $(1, 10)$  \n",
    "* Входные данные в `data/sonar.csv`\n",
    "* scoring - `precision`\n",
    "* cv - $5$\n",
    "* Другие параметры в `DecisionTreeClassifier` не указывать.\n",
    "\n",
    "Не нужно Shuffl-ить данные, это может повлиять на ответ и в итоге задача не зачтется."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def fit_gs(X: np.ndarray, y: np.ndarray) ->  GridSearchCV:\n",
    "    dt = DecisionTreeClassifier(\n",
    "        max_depth=3,\n",
    "        min_samples_leaf=3,\n",
    "\n",
    "    )\n",
    "    params = {'max_depth': list(range(2, 100)), 'min_samples_leaf': [2, 3, 4]}\n",
    "    gs = GridSearchCV(\n",
    "        estimator=dt, \n",
    "        param_grid=params, \n",
    "        cv=5, \n",
    "        scoring='precision')\n",
    "    gs.fit(X, y)\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 4, 'min_samples_leaf': 3}\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv('data/sonar.csv').drop(columns=['y']).values\n",
    "Y = pd.read_csv('data/sonar.csv')['y']\n",
    "######################################################\n",
    "gs = fit_gs(X,Y)\n",
    "\n",
    "print(gs.best_params_)\n",
    "\n",
    "assert gs.best_params_['max_depth'] == 4\n",
    "assert gs.best_params_['min_samples_leaf'] == 3\n",
    "assert np.abs(gs.best_score_ - 0.7829244) < 0.001\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Удаление Nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Серия задач в данном модуле объединена в одну [большую задачу по предсказанию данных](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview). В ходе выполнения модуля мы будем разбирать определенные техники, которые нужны для ее решения. Настоятельно рекомендуем выполнить все шаги **по порядку**, тогда в конце вы получите решение большой реальной задачи по МЛ.\n",
    "\n",
    "Нам даны [данные](https://yadi.sk/d/tcElz6cqSNpPqA) о домах выставленных на продажу. Нам необходимо решить задачу регрессии и предсказать цену продажи дома для $X_{test}$ по данным $X_{train}$ и $y_{train}$. В нашем случае  $y_{train}$ - это столбик `SalePrice`, $X_{train}$ - все остальные столбики.\n",
    "\n",
    "На вход подается 2 считанных датафрейма **df_train**, **df_test** из файлов без изменений. \n",
    "\n",
    "Начальная подготовка:\n",
    "\n",
    "* Разделить **df_train** на **X_train**(`pd.Dataframe`) и **y_train**(`pd.Series`).\n",
    "* Сконкатенировать **X_train** и **df_test** в **df** по вертикали (можно ориентироваться по столбику `Id` они как раз идут по-порядку). Не забудьте обновить индекс!\n",
    "\n",
    "Задачи:\n",
    "\n",
    "* Заменить в **df** все Nan-ы в категориальных признаках (`object`) на строку `missing`\n",
    "* Заменить в **df** все Nan-ы в числовых признаках на 0.\n",
    "\n",
    "Вернуть из функции измененный **df**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def del_nan(df_train: pd.DataFrame, df_test: pd.DataFrame) -> pd.DataFrame:\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "del_nan_df = pd.read_csv('data/del_nan.csv')\n",
    "######################################################\n",
    "assert_frame_equal(del_nan(train, test), del_nan_df)\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Порядковые категории"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам на вход приходит **df** из предыдущей задачи.\n",
    "\n",
    "Если внимательно изучить файл `data_description` можно понять, что многие категориальные признаки - порядковые (упорядоченное множество). Значит их можно перевести в осмысленные числа. Значит тут можно воспользоваться `LabelEncoding`.\n",
    "\n",
    "Ваша задача: заменить в **df** категориальные признаки на числовые, для порядковых признаков.\n",
    "\n",
    "На выходе возвращаем измененный **df**.\n",
    "\n",
    "Чтобы слегка упростить вам жизнь, вот вам готовые словари для перевода. Однако к каким столбцам их применять - вы должны выяснить сами, изучив файл `data_description`. Каждый маппинг используется хотя бы 1 раз, а некоторые и не по одному разу.\n",
    "\n",
    "```python\n",
    "{'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'missing':0}\n",
    "{'Gd':4, 'Av': 3, 'Mn': 2, 'No': 1, 'missing': 0}\n",
    "{'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, 'missing': 0}\n",
    "{'Typ': 8, 'Min1': 7, 'Min2': 6, 'Mod': 5, 'Maj1': 4, 'Maj2': 3, 'Sev': 2, 'Sal': 1, 'missing': 0}\n",
    "{'Fin': 3, 'RFn': 2, 'Unf': 1, 'missing': 0}\n",
    "{'GdPrv': 4, 'MnPrv': 3, 'GdWo': 2, 'MnWw': 1, 'missing': 0}\n",
    "{'Reg': 4, 'IR1': 3, 'IR2': 2, 'IR3': 1, 'missing': 0}\n",
    "{'Lvl': 4, 'Bnk': 3, 'HLS':2,'Low':1, 'missing': 0}\n",
    "{'AllPub':4, 'NoSewr':3, 'NoSeWa':2, 'ELO':1, 'missing':0}\n",
    "{'Gtl':3, 'Mod':2, 'Sev':1, 'missing':0}\n",
    "{'SBrkr':5, 'FuseA':4, 'FuseF':3, 'FuseP':2, 'Mix':1, 'missing':0}\n",
    "{'Y':3, 'P':2, 'N':1, 'missing':0}\n",
    "{'Y':1, 'N':0, 'missing':0} #тут нет ошибки, все так и задумано:)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hint\n",
    "После перевода у вас должно **остаться** 20 категориальных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def cat_to_num(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_nan_df = pd.read_csv('data/del_nan.csv')\n",
    "answer = pd.read_csv('data/cat_to_num.csv')\n",
    "######################################################\n",
    "cat_to_num_df = cat_to_num(del_nan_df)\n",
    "assert_frame_equal(cat_to_num_df, answer)\n",
    "\n",
    "categorical_cols = [col for col in cat_to_num_df.columns if cat_to_num_df[col].dtypes == \"object\"]\n",
    "assert len(categorical_cols) == 20\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. One hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь разберемся с непорядковыми категориальными признаками.\n",
    "\n",
    "Для начала заметим признак `MSSubClass`, у которого тип `int64`, но если посмотреть в описание `data_description` можно понять, что это - категориальный признак. \n",
    "\n",
    "* Измените тип признака `MSSubClass` с `int64` на `object`\n",
    "\n",
    "Теперь можно сделать `One hot encoding`:\n",
    "\n",
    "* Найдите все колонки с категориальными признаками и составьте из них отдельный **df_oh** `pd.DataFrame` (индекс сохранить прежний)\n",
    "* Применить к полученному фрейму **df_oh** функцию [`pd.get_dummies`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) (Реализует `One Hot Encoding`)\n",
    "* Удалить категориальные колонки из **df** и добавить справа к **df** фрейм с `One Hot Encoding`\n",
    " \n",
    "Вернуть из функции **df**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hint\n",
    "Итого должно получится 238 колонка из них 179 пришли из `One hot encoding` фрейма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def one_hot(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_to_num_df = pd.read_csv('data/cat_to_num.csv')\n",
    "one_hot_ans = pd.read_csv('data/one_hot.csv')\n",
    "######################################################\n",
    "one_hot_df = one_hot(cat_to_num_df)\n",
    "assert_frame_equal(one_hot_df.astype('float64').reindex(sorted(one_hot_df.columns), axis=1), \n",
    "                   one_hot_ans.astype('float64').reindex(sorted(one_hot_ans.columns), axis=1))\n",
    "\n",
    "assert one_hot_df.shape[1] == 238\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Некоррелирующие признаки "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы разобрались с категориальными признаками, теперь разберемся с числовыми.\n",
    "Для числовых признаков можно посчитать корреляцию с правильным ответом. Если признаки слабо коррелируют, то они нам не нужны. Например колонка `Id` явно никак не влияет на стоимость дома.\n",
    "\n",
    "Вам на вход передается изначальный **df_train** и **df** полученный из предыдущей задачи.\n",
    "\n",
    "Ваша задача: \n",
    "\n",
    "* найти корреляцию всех **числовых** признаков **df_train** с признаком `SalePrice` с помощью `pd.corr`\n",
    "* если абсолютное значение корреляции признака с `SalePrice` меньше $0.05$ - удалите этот признак из **df**\n",
    "\n",
    "Верните измененный **df** и столбец корреляции признаков с признаком `SalePrice` упорядоченный по убыванию. Начало столбца корреляции выглядит следующим образом:\n",
    "\n",
    "|               |SalePrice |\n",
    "|---------------|----------|\n",
    "|**SalePrice**  |1.000000  |\n",
    "|**OverallQual**|0.790982  |\n",
    "|**GrLivArea**  |0.708624  |\n",
    "|**GarageCars** |0.640409  |\n",
    "|**GarageArea** |0.623431  |\n",
    "|**TotalBsmtSF**|0.613581  |\n",
    "|**1stFlrSF**   |0.605852  |\n",
    "|**FullBath**   |0.560664  |\n",
    "\n",
    "Всего должно получиться 37 числовых признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(df: pd.DataFrame, df_train: pd.DataFrame) -> (pd.DataFrame, pd.DataFrame):\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_df = pd.read_csv('data/one_hot.csv')\n",
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "ans_corr_df = pd.read_csv('data/corr_df.csv')\n",
    "ans_corr = pd.read_csv('data/corr.csv').set_index('Unnamed: 0')\n",
    "######################################################\n",
    "corr_df, corr = correlation(one_hot_df, df_train)\n",
    "\n",
    "assert_frame_equal(corr_df.astype('float64').reindex(sorted(corr_df.columns), axis=1),\n",
    "                   ans_corr_df.astype('float64').reindex(sorted(ans_corr_df.columns), axis=1))\n",
    "\n",
    "assert_array_almost_equal(corr.values, ans_corr.values, decimal=4)\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Feature Engineering и Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу 2 простые задачки:\n",
    "\n",
    "1) Давайте нагенерируем несколько фич во входном фрейме **df**:\n",
    "\n",
    "    * `TotalArea` = `TotalBsmtSF` + `1stFlrSF` + `2ndFlrSF` + `GrLivArea` + `GarageArea`\n",
    "    * `YearAverage` = (`YearRemodAdd` + `YearBuilt`) / 2\n",
    "    * `LiveAreaQual` = `OverallQual` * `GrLivArea`\n",
    "\n",
    "    На выход отправьте **df** c тремя новымим столбиками. столбцы должны идти в том же порядки что указаны в списке в хвосте **df**.\n",
    "\n",
    "2) У стандартного и нормального масштабирования есть одна проблема: она учитывает все признаки, даже те, которые изначально некорректны (шум, выбросы). Чтобы избавитьться от шумов и выбросов и корректно масштабировать выборку необходимо использовать [RobustScaling](https://scikit-learn.org/0.18/auto_examples/preprocessing/plot_robust_scaling.html).\n",
    "\n",
    "    Ваша задача - отмасштабировать полученный фрейм с помощью `RobustScaler`. И вернуть отмасштабированный массив (да, скалирование возвращает массив, а не DataFrame)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def feature_en(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass\n",
    "\n",
    "def scaling(df: pd.DataFrame) -> np.array:\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = pd.read_csv('data/corr_df.csv')\n",
    "ans_feature_df = pd.read_csv('data/feature_df.csv')\n",
    "######################################################\n",
    "\n",
    "feature_df = feature_en(corr_df)\n",
    "\n",
    "assert_frame_equal(feature_df.astype('float64').reindex(sorted(feature_df.columns), axis=1),\n",
    "                   ans_feature_df.astype('float64').reindex(sorted(ans_feature_df.columns), axis=1))\n",
    "######################################################\n",
    "feature_df = pd.read_csv('data/feature_df.csv')\n",
    "ans_scale_df = pd.read_csv('data/scale_df.csv').values\n",
    "######################################################\n",
    "\n",
    "scale_df = scaling(feature_df)\n",
    "\n",
    "assert_array_almost_equal(scale_df,\n",
    "                          ans_scale_df,\n",
    "                          decimal=6)\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Смешанная модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, теперь мы готовы обучать модель! Осталось изучить последний интересный трюк - смешанные модели.\n",
    "\n",
    "Возьмем [2 регрессии](https://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b):\n",
    "\n",
    "* Ridge\n",
    "* Lasso\n",
    " \n",
    "Найдем оптимальные значения $\\alpha$ для обеих регрессий с помощью GridSearch.\n",
    "\n",
    "Теперь отправим обе модели с наилучшими параметрами в класс указанный снизу. Это класс смешения моделей. В нем параметр $\\beta \\in [0,1]$ - это коэффициент, с которым берется ответ одного классификаторв, а ответ второго - с коэффициентом $(1 - \\beta)$. Такая техника нередко позволяет добиться лучших результатов, чем одна модель.\n",
    "\n",
    "Теперь найдем наилучшее $\\beta$ для смешенной модели также с помощью GridSearch. Осталось получить **y_pred** с помощью наилучшей смешанной модели.\n",
    "\n",
    "На вход вы получаете **X_scaled** из предыдущей задачи и **df_train** начальный. Мы подготовили за вас **X_train**, **y_train** и **X_test**. \n",
    "\n",
    "В задаче необходимо минимизировать метрику `neg_mean_squared_log_error`. Для удобства мы возьмем `np.log1p(y_train)` и будем минимизировать метрику `neg_mean_squared_error`. Эту метрику необходимо минимизировать у всех 3-х GridSearch.\n",
    "\n",
    "На выход отправьте GridSearch объект смешанной модели, а также результат **y_test**. (Не забудьте его проэкспоненциировать).\n",
    "\n",
    "Мы выдаем вам ориентировачные параметры для каждого GridSearch. Вы можете увеличить перебор, чтобы получить лучшую модель.\n",
    "```python\n",
    "params_ridge = {'alpha': np.arange(1, 20)}\n",
    "params_lasso = {'alpha': np.logspace(-4, 3, num=8, base=10)}\n",
    "params_blend = {'beta': np.linspace(0, 1, 11)}\n",
    "```\n",
    "\n",
    "Первые 2 GridSearch **не нужно** писать в функции: они могут работать достаточно долго и превысят лимит работы задачи на сервере. Найдите у себя локально наилучшие параметры и уже с этими параметрами создайте смешанную модель внутри функции. \n",
    "\n",
    "Также не нужно сильно увеличивать перебор для $\\beta$ - того, что есть, более чем достаточно.\n",
    "\n",
    "P.S. Осталось сохранить файл с **y_test** и отправить его в [соревнование](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/submit). \n",
    "\n",
    "Улучшайте свои результы пробуя другие модели и другие параметры. Уберите больше ненужных признаков, добавьте новые фичи. Экспериментируйте и дерзайте!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "class BlendRegressor(BaseEstimator): # предок класса классификаторов, чтобы можно было засунуть в GridSearch\n",
    "    def __init__(self, clf1, clf2, beta=0.5):\n",
    "        self.clf1 = clf1 \n",
    "        self.clf2 = clf2\n",
    "        self.beta = beta #параметр смешивания\n",
    "\n",
    "    def fit(self, X, y): #обучаем классификатор\n",
    "        self.X_ = X\n",
    "        self.y_ = y \n",
    "        self.clf1.fit(X, y)\n",
    "        self.clf2.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X): #возвращаем значения \n",
    "        return self.clf1.predict(X) * self.beta + self.clf2.predict(X) * (1 - self.beta)\n",
    "\n",
    "    \n",
    "def learning(X_scaled: np.array, df_train: pd.DataFrame) -> (GridSearchCV, np.array):\n",
    "    X_train = X_scaled[0: len(df_train),]\n",
    "    X_test  = X_scaled[len(df_train): len(X_scaled)]\n",
    "    y_train = np.log1p(df_train['SalePrice'])\n",
    "    \n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    \n",
    "    return blend_gs, np.exp(y_test) - 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
